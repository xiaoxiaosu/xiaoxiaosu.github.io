<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[高性能Mysq读书笔记]]></title>
    <url>%2F2020%2F07%2F14%2F%E9%AB%98%E6%80%A7%E8%83%BDMysq%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Mysql服务器逻辑架构 第一层 客户端第二层 MySQL核心服务功能包含查询解析，分析，优化，缓存以及所有的内置函数（日期，时间，数学，加密） 所有跨存储引擎的功能都在这一层：存储过程、触发器、视图 第三层存储引擎负责MySQL中数据的存储和提取。 服务器通过API与存储引擎进行通信。 这些接口屏蔽了不同存储引擎之间存在的差异，使得这些差异对上层的查询过程透明。 不同的存储引擎之间不会相互通信，只是简单的响应上层服务器的请求 MySQL执行过程 客户端发送一条查询给服务器 服务器先检查查询缓存，如果命中了缓存，则立刻返回存储在缓存中的结果，否则进入下一个阶段 服务器端进行SQL解析，预处理，再由优化器生成对应的执行计划 MySQL根据优化器生成的执行计划，调用存储引擎的API来执行查询 将结果返回客户端 数据类型优化更小的通常更好越简单的数据类型越好 通常越简单的数据类型占用资源约小 用整形代替字符串 用自带类型代替字符串（date,time,datetime） 尽量避免使用NULL 通常情况下最好指定列为NOT NULL，除非真的需要存储NULL值 可为NULL的列使得索引，索引统计和值比较都更复杂 可为NULL的列使用更多存储空间，在MySQL里需要特殊处理 可为NULL的列被索引时，每个索引需要一个额外的字节 InnoDB使用单独的位存储NULL值 DateTime与TIMESTAMP TIMESTAMP只使用DateTime一半的存储空间，根据时区变化，可自动更新 TIMESTAMP允许的时间范围小的多，有时候特殊能力会成为障碍 整数类型 TINYINT，SMALLINT,MEDIUMINT,INT,BIGINT,分别占用8，16，24，32，64位存储空间，可以存储的范围为-2^(n-1)~2^(n-1)-1，其中n是存储空间的位数 有符号和无符号类型使用相同的存储空间，并具有相同的性能 MySQL可以为整数类型指定宽度，对大多数应用是没有意义的，这不会限制值的合法范围，只是规定了一些交互工具用来显示字符的个数，int(1)和int(10)所占用的存储空间是一样的 Varchar和CharVARCHAR Varchar类型用于存储可变长的字符串，是最常见的字符串类型。比定长类型更节省空间，因为它仅使用必要的空间，越短的字符串使用越少的空间。 Varchar需要使用1或2个额外的字节记录字符串的长度，如果列的长度小于或等于225个字节，就只使用1个字节表示，否则使用2个字节。 Varchar在更新的时候，如果新的数据比原来的数据长，所在行占用的空间增长，并且在页内没有更多的空间可以存储，这种情况下容易产生数据碎片。 以下情况适合使用Varchar 字符串列的最大长度比平均长度大很多 列的更新很少 UTF-8这样的复杂字符集，每个字符都使用不同的字节数进行存储 CHAR Char类型是定长的，MySQL总是根据定义的字符串长度分配足够的空间 当存储Char值时，MySQL会删除所有末尾的空格 以下情况适合使用Char 存储很短的字符串，或者所有值都接近一个长度 对于经常变更的数据，不容易产生数据碎片 Enum 枚举类可以把一些不重复的字符串存储成一个预定义的集合 MySQL在存储枚举时非常紧凑，会根据列表值的数量压缩到一个或两个字节中 枚举字段的排序是按照内部存储的正数而不是定义的字符串进行的 枚举不好的地方是字符串列表是固定的，添加或删除字符串必须使用ALTER TABLE 使用ENUM比起使用VARCHAR更节约空间 设计表结构时可能遇到的问题太多的列MySQL存储引擎API工作时需要在服务器层和存储引擎层之间通过行缓冲格式拷贝数据，然后在服务器层将缓冲内容解码成各个列。从行缓冲中将编码过的列转换成行数据结构的代价是非常高的 太多的关联优化Alter Table 的效率1、先在一台不提供服务的机器上执行ALTER TABLE操作，然后和提供服务的主库进行切换 2、创建一张相同结构的新表，将数据写入后，删除原表，新表更名为原表 索引优点 索引大大减少了服务器需要扫描的数据量 索引可以帮助服务器避免排序和临时表 索引可以将随机I/O变为顺序I/O 独立的列Where条件中不能包含表达式，否则不能执行索引,例如下面的语句 1select actor_id from actor where actor_id + 1 = 5; 模拟哈希索引有时候需要索引很长的字符列，我们可以模拟哈希索引的方式先用一个哈希函数将字符串转为数字，然后用单独的转换后的列作为索引，并在查询时带上对应的哈希值 前缀索引对于需要索引很长的字符列的情况，我们也可以通过前缀索引进行优化 通常可以索引开始部分的字符，这样可以大大节约索引空间，从而提高索引效率。 前缀索引的要点在于索引选择性，索引选择性指（不重复的索引值/数据总条数） 1234567select count(distinct city)/count(*) from cities; #resaselect count (distinct left(city,3))/count(*) as sel3, count (distinct left(city,4))/count(*) as sel4, count (distinct left(city,5))/count(*) as sel5, count (distinct left(city,3))/count(*) as sel3, #resb 计算出最接近resa的resb的值 多列索引 在多个列上单独建立索引，在大多数情况下并不能提升MySQL的查询性能 12345678 CREATE TABLE `film_actor` ( `id` int(11) NOT NULL AUTO_INCREMENT, `actor_id` int(11) NOT NULL DEFAULT '0', `film_id` int(11) NOT NULL DEFAULT '0', PRIMARY KEY (`id`), KEY `film_id` (`film_id`), KEY `actor_id` (`actor_id`),) ENGINE=InnoDB AUTO_INCREMENT=9 DEFAULT CHARSET=latin1 当执行 1select * from film_actor where actor_id=1 or film_id=2; Mysql 会对两个单独的索引进行扫描并将结果合并 这种算法有3个变种：OR(union),AND(intersection),组合OR和AND 通过 1explain select * from film_actor where actor_id=1 or film_id=2; 可以看到 Extra列，返回了Using union(PRIMARY,idx_fk_film_id);using where 这个操作是MySQL对查询进行优化的结果，这也说明了索引建立的有问题 当MySQL对多个索引进行了相交操作时，意味着需要一个包含多个相关列的联合索引，而不是多个独立的单列索引 当MySQL需要对多个索引做联合操作的时候，通常需要消耗大量的CPU和内存资源在算法的缓存，合并和排序操作上 优化器不会把上述计算算到查询成本中，这会使得查询成本被低估，导致执行该计划还不如走全表扫描 聚簇索引 聚簇索引是一种数据的存放方式 聚簇索引在Innodb中就是主键索引 Myisam 索引数据分布在Myisam中主键索引和其他索引在结构上没有区别，都是指向了数据对应的行，主键索引是唯一非空索引 InnoDB 索引数据分布如图所示，Innodb中聚簇索引存放了整行的数据 聚簇索引的每一个叶子节点包含了主键值，事务id，用于事务和MVCC的回滚指针以及所有剩余列。 InnoDB的二级索引的叶子节点中存储的不是行指针而是主键值，这样的策略减少了当出现移动或者数据页分裂时二级索引的维护工作 聚簇索引中要避免随机（不连续且值分布很大）的聚簇索引因为主键的值是顺序的，索引Innodb把每一条记录都存储在上一条的记录后面，当达到页的最大填充因子时，下一条记录就会写入新页中。 如果主键的值不是顺序的，Innodb需要为新的行寻找合适的位置，并且分配空间，这会增加很多额外的工作并且产生数据碎片 覆盖索引 如果 ‘一个’索引覆盖所有查询字段的值，我们就称之为覆盖索引 索引条目通常远小于数据行大小，所有如果只需要读取索引，那么MySQL就会极大的减少数据访问量 因为索引是按照列值顺序存储的，所以对于I/O密集型的范围查询会比随机从磁盘中读取一行数据的I/O要少得多 一些存储引擎例如Myisam在内存中只缓存索引，数据依赖于操作系统来缓存，因此要访问数据需要一次系统调用，这可能会导致严重的性能问题 由于InnoDB的聚簇索引，覆盖索引对InnoDB表特别有用，InnoDB的二级索引在叶子节点中保存了行的主键值，所以如果二级索引如果能覆盖查询，则可以避免回表查询（Myisam不行） 当发起一个覆盖索引的查询时，在explain的extra列可以看到“using index”的信息 总结 单行访问是很慢的，如果服务器从存储中读取一个数据块只是为了获取其中一行，那么就浪费了很多工作，最好读取的块中能包含尽可能多所需要的行 按顺序访问是很快的，第一，顺序I/O不需要多次磁盘寻道，所以比随机I/O快很多，如果服务器能够按需要顺序读取数据，那么就不需要再进行额外的排序操作，并且GROUP BY查询也无需再做排序和将行按组进行聚合查询了 索引覆盖查询是很快的，如果一个索引包含了查询需要的所有列，那么存储引擎就不需要再回表查找行。这避免大量的单行访问， 查询优化影响查询开销的指标响应时间​ 响应时间为服务时间+排队时间 ​ 服务时间是指数据库处理这个查询真正花了多长时间 ​ 排队时间是指服务器因为等待某些资源而没有真正执行查询的时间 扫描的行数与返回的行数​ 理想情况下扫描的行数和返回的行数应该相等 ​ 但是在做关联查询的时候返回一条数据可能需要扫描多条数据 扫描的行数和访问类型​ 在EXPLAIN语句中的type列反应了访问类型，其中包括： ​ 全表扫描、索引扫描、范围扫描、唯一索引查询、常数引用 ​ 从左到右，速度由慢到快 MySQL使用WHERE条件的方式 在索引中使用WHERE条件来过滤不匹配的记录。这是在存储引擎层完成的 使用索引覆盖扫描（在Extra列中出现了Using Index）来返回记录，直接从索引中过滤不需要的记录并返回命中的结果。这是在MySQL服务器层返回的，但无需再回表查询记录。 从数据表中返回数据，然后过滤不满足条件的记录（在Extra列中出现了Using Where）。这是在MySQL服务器层完成的，MySQL需要先从数据表读出记录然后再过滤。 重构查询一个复杂查询还是多个简单查询一台通用的服务器上，能够运行每秒超过十万次的查询，一个千兆网卡能轻松满足每秒超过2000次的查询，所以将一个复杂的查询拆分成多个小查询是ok的。 MySQL内部每秒能够扫描内存中上百万行数据，相比之下，MySQL响应数据给客户端就慢的多了，所以在其他条件都相同的时候，使用尽可能少的查询是更好的。 切分查询有时候对于一个大查询，我们需要切分成多个小查询，每次只返回一小部分查询结果。 删除旧数据是一个很好的例子。定期的清除大量的数据时，如果用一个大的语句一次性完成的话，则可能需要一次性锁住很多数据，占满整个事务日志，耗尽系统资源，阻塞很多小的但是重要的查询。 一次性删除一万行数据一般来说是一个比较高效而且对服务器影响最小的做法 如果每次删除数据后，都暂停一会儿再做下次删除，这样可以将服务器原本一次性的压力分散到一个很长的时间段中，就可以大大降低对服务器的影响，还可以大大减少删除时锁的持有时间。 分解关联查询很多高性能的引用都会对关联查询进行分解。 将一条查询分解成多条查询，其中的优势如下： 让缓存的效率更高。许多应用程序可以方便的缓存单表查询对应的结果对象。 将查询分解后，执行单个查询可以减少锁的竞争。 查询本身的效率也会提升。 可以减少冗余记录的查询。在应用层做关联查询，意味着对于某条记录应用只需要查询一次，而在数据库中做关联查询，则可能重复的访问一部分数据。从这点看，这样的重构还可能会减少网络和内存的消耗。 这样做相当于在应用中实现了哈希关联，而不是使用MySQL的嵌套循环关联。 MySQL查询执行的基础MySQL客户端/服务器通信协议MySQL客户端和服务器之间的通信协议是“半双工的”，这意味着在任何一个时刻，要么是由服务器向客户端发送数据，要么是由客户端向服务器发送数据，这两个动作不能同时发生。 这种协议让MySQL通信简单快速，但是也从很多地方限制了MySQL。一个明显的限制是，这意味着没法进行流量控制。一旦一段开始发出消息，另一端要接收完整个消息才能响应它。 客户端用一个单独的数据包将查询传给服务器，这也是为什么当查询的语句很长的时候，参数max_allowed_packet就特别重要了。 一般服务器响应给客户度的数据通常很多，由多个数据包组成。当服务器开始响应的时候客户端请求的时候，客户端必须完整的接收整个返回结果，而不能简单的只取前面几条结果。 当客户端从服务器取数据时，看起来是一个拉数据的过程，但实际上是MySQL在向客户端推数据的过程。 多数连接MySQL的库函数都可以获得全部结果集并缓存到内存里，还可以逐行获取需要的数据。默认一般是获得全部结果集并缓存到内存中。MySQL通常需要等待所有的数据都已经发送给客户端才能释放这条查询所占用的资源，所以接收全部结果并缓存通常可以减少服务器的压力，让查询能够早点结束，早点释放相应的资源。 当使用多数连接MySQL的库函数从MySQL获取数据时，其结果看起来都像是从MySQL服务器获取数据，而实际上是从这个库函数的缓存获取数据。多数情况下这没什么问题，但是如果需要返回一个很大的结果集的时候，这样做并不好，因为库函数会话很多时间和内存来存储所有的结果集。 123456&lt;?php$link = mysql_connect('localhost','user','password');$result = mysql_query("select * from table", $link);while ($row = mysql_fetch_array($result)) &#123; &#125; 这段代码看起来像是只有当你需要的时候，才通过循环从服务器取出数据，实际上在调用mysql_query()的时候，php就已经将整个结果集缓存到内存中，下面的while循环只是从这个缓存中逐行取出数据。 查询缓存在解析一个查询语句之前，如果查询缓存是打开的，那么MySQL会优先检查这个查询是否命中了查询缓存中的数据，这个检查是通过一个对大小写敏感的哈希查找实现的。 查询优化处理语法解析器和预处理器首先，MySQL通过关键字将SQL语句进行解析，并生成一棵对应的“解析树”。 MySQL解析器将使用MySQL语法规则验证和解析查询。例如，它将验证是否使用错误的关键字，或者使用的关键字的顺序是否正确等，再或者它还会验证引号是否前后能正确匹配。 预处理器则根据一些MySQL规则进一步检查解析树是否合法，例如，这里检查数据表和数据列是否存在，还会解析名字和别名，看看是否有歧义。同时预处理器会验证权限。 查询优化器到这一步时，语法树被认为是合法的了，并且优化器将其转换成执行计划。 一条查询可以有很多执行方式，最后都返回相同的结果。优化器的作用就是找到这其中最好的执行计划。 MySQL使用基于成本的优化器，它将预测一个查询使用某种执行计划时的成本，并选择其中成本最小的一个。 排序优化 无论如何排序都是一个成本很高的操作，从性能的角度，应尽可能避免排序或者避免对大量数据进行排序 当不能使用索引生成排序结果时，MySQL需要自己进行排序，如果数据量小就在内存中进行，如果数据量大就在磁盘中，这个过程叫做file sort。 如果需要排序的数据量小于排序缓冲区，MySQL会使用内存进行快速排序操作。 如果内存不够，那么MySQL会先将数据分块，对每个独立的块使用快速排序，并将排序结果放在磁盘上，然后将各个排序好的结果进行合并成。 MySQL使用如下排序算法： 先读取查询所需要的列，然后再根据给定的列进行排序，最后直接返回排序后的结果。 MySQL在进行文件排序的时候需要使用非常大的临时存储空间，因为MySQL在排序时，对每一个排序记录都会分配一个足够长的定长空间来存放。 这个定长空间必须足够长可以容纳其中最长的字符串，如果是VARCHAR列则需要分配完整的长度，如果是UTF8字符集，则为每个字符要预留三个二字节的长度，所以排序时消耗的临时空间可能远大于原表所占用的磁盘空间。 特定SQL的优化countcount(*) 并不会像我么猜想的那样扩展所有的列，实际上是忽略所有的列而直接统计所有的行数 带where子句的统计行数，myisam和别的存储引擎没有任何不同 select count(*) from city where id&gt;5 会扫描很多数据 select (select count() from city) -count() from city where id&lt;=5 只会扫描6行数据 select count(color=’gray’ or null) as gray,count(color=’yelow’ or null) as yellow from items 可以通过这一条语句统计多个类型的值的条数 关联查询 确保ON或者USING子句中的列有索引。在创建索引的时候就要考虑到关联的顺序，一般来说，除非有其他理由，否则只需要在关联顺序的第二个表的相应列上创建索引 确保任何group by和order by的表达式中只涉及到一个表的列，这样MySQL才有可能使用索引来优化这个过程。 子查询尽量别用子查询吧hhhhh GROUP BY和DISTINCT]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言核心编程读书笔记]]></title>
    <url>%2F2020%2F07%2F01%2FGo%E8%AF%AD%E8%A8%80%E6%A0%B8%E5%BF%83%E7%BC%96%E7%A8%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[数组，字符串，切片数组数组是值类型，虽然数组元素的值可以被修改，但是数组本身的赋值和函数传参，都是以整体复制的方式处理的。 数组是一个由固定长度的特定类型的元素组成的序列，一个数组可以由零个或者多个元素组成。 数组的长度是数组类型的组成部分，因为数组的长度是数组类型的一个部分，不同长度的或者不同类型的数据组成的数组都是不同类型的数组，无法直接赋值。 数组的定义方式12var a [3]intvar b = [...]int&#123;1,2,3&#125; 数组内存结构Go语言中的数组是值语义，一个数组变量既表示整个数组，并不是隐式的指向第一个元素的指针。 当一个数组变量被赋值或者传递时，实际上会复制整个数组。 空数组长度为0的数组在内存中不占用空间，空数组可以用于强调某种特有类型的操作时避免分配额外的内存 1234c1 := make(chan [0]int)go func() &#123; c1 &lt;- [0]int&#123;&#125;&#125;() 内置函数12len() //计算数组的长度cap() //计算数组的容量 字符串GO语言字符串的底层数据也是对应的字节数组，但是字符串的只读属性禁止了在程序中对底层字节数组的元素进行修改。 字符串赋值只是复制了数据地址和对应的长度，而不会导致底层数据的复制 底层结构1234type StringHeader struct &#123; Data uintptr //指向底层的字节数组 Len int //字符串的字节长度&#125; 切片切片的底层数据也是数组，但是每个切片还有独立的长度和容量信息，切片赋值和函数传参时也是将切片头信息部分按传值方式处理。因为切片头含有底层数组的指针，所以它的赋值也不会导致底层数组的复制 底层结构12345type SliceHeader struct &#123; Data uintptr Len int Cap int&#125; 切片的定义123456789var ( a []int //nil切片，和nil相等，一般用来表示一个不存在的切片 b = []int&#123;&#125; //空切片，和nil不相等，一般用来表示一个空的集合 c = []int&#123;1,2,3&#125; //有三个元素的切片，len和cap都为3 d = c[:2] //有两个元素的切片 len=2 cap=3 e = c[:0] //0个元素的切片 len=0 cap=3 f = make([]int,3) //有三个元素的切片 len=3 cap=3 g = make([]int,3,6) //有三个元素的切片 len=3 cap=6) 相关知识切片可以和nil进行比较，只有当切片底层数据指针为空时，切片本身为nil，这时候切片的长度和容量信息将是无效的 在对切片本身赋值或参数传递时，和数组指针的操作类似，只是复制切片头信息，并不会复制底层的数据 内置函数1append() // 增加切片元素，在容量不足的情况下，append操作会导致重新分配内存，可能导致巨大的内存分配和复制数据代价 切片内存技巧 切片高效操作的要点是降低内存分配的次数，尽量保证append操作不会超出cap的容量，降低触发内存分配的次数和每次分配内存的大小 12345678910111213141516171819202122232425262728293031323334// 扩容切片a = append(a, 0) //切片扩展一个空间copy(a[i+1:], a[i:]) //a[i:] 向后移一位a[i] = x //设置新添加的元素//删除切片元素a = []int&#123;1,2,3&#125;a = a[:len(a)-1]a = a[1:]//利用空切片的特性删除切片元素func TrimSpace(s []byte) []byte &#123; b := [s:0] for _,x := range s &#123; if x != ' ' &#123; b = append(b, x) &#125; &#125; return b&#125;//提高GC效率func FindPhoneNum(filename string) []byte &#123; b, _ := ioutil.ReadFile(filename) return regexp.MustCompile("[0-9]+").Find(b)&#125;/*这段代码返回的[]byte指向保存整个文件的数组，因为切片引用了整个原始数组，导致自动垃圾回收器不能及时释放底层数组的空间，一个小的需求可能导致需要长时间保存整个文件数据。通过下面的方式进行优化*/func FindPhoneNum(filename string) []byte &#123; b, _ := ioutil.ReadFile(filename) regexp.MustCompile("[0-9]+").Find(b) return append([]byte&#123;&#125;, b...)&#125; 函数，方法与接口函数在GO语言中，函数是第一类对象，我们可以将函数保存到变量中。 123456789//具名函数func Add(a, b int) int &#123; return a+b&#125;//匿名函数var Add = func(a, b int) int &#123; return a+b&#125; 闭包 一般我们把匿名函数捕获了外部函数的局部变量的函数称为匿名函数 1234567891011121314func main() &#123; for i:=0; i &lt; 3; i++ &#123; defer func()&#123;println(i)&#125;() &#125;&#125;//3//3//3//因为闭包，每个defer语句延迟执行的函数引用的都是同一个i迭代变量，在循环结束后，i都为3，可以通过以下方法解决该问题func main() &#123; for i:=0; i&lt;3; i++ &#123; defer func()&#123;println(i)&#125;(i) &#125;&#125; 切片作为入参GO语言中，如果以切片作为参数调用函数时，有时候会给人一种参数采用了引用方式传递的假象：因为在被调用函数内部可以修改传入的切片元素。其实，任何可以通过函数参数修改调用参数的情形，都是因为函数参数中显示或者隐式的传入了指针参数。 因为切片中的底层数组部分是通过隐式指针传递（指针本身依然是传值的，但是指针指向的却是同一份数据）,所以被调用函数是可以通过指针修改调用参数切片中的数据。除了数据之外，切片结构还包含了切片长度和切片容量的信息，这两个信息也是传值的，如果被调用函数中修改了Len或Cap信息的话，就无法反映到调用参数的切片中，这时候我们一般会通过返回修改后的切片来更新之前的切片，这也是为什么内置的append必须要返回一个切片的原因 1234567891011121314151617func twice(x []int) &#123; for i := range x &#123; x[i] *= 2 &#125;&#125;type IntSliceHeader struct &#123; Data []int Len int Cap int&#125;func twice(x IntSliceHeader) &#123; for i:=0; i &lt; x.Len; i++ &#123; x.Data[i] *= 2 &#125;&#125; 递归GO语言函数的递归调用深度逻辑上没有限制，函数调用的栈是不会出现溢出错误的，因为GO语言运行时会根据需要动态的调整函数栈的大小。每个goroutine刚启动时只会分配很小的栈，根据需要动态调整栈的大小。 方法GO语言中方法是关联到类型的，这样可以在编译阶段完成方法的静态绑定。 组合123456type Point struct&#123;X, Y float64&#125;type ColorPoint struct &#123; Point Color color.RGBA&#125; 接口&gt; Go的接口类型是对其他类型行为的抽象和概括，Go语言的接口类型独特之处在于它是满足隐式实现的鸭子类型 这种设计可以让你创建一个新的接口类型满足已经存在的的具体类型却不用去破坏这些类型原有的定义，当我们使用的类型来自于不受我们控制的包时，这种设计尤其灵活有用。 接口在Go语言中无处不在 123456789101112131415161718192021222324func Fprintf(w io.Writer, format string, args ...interface&#123;&#125;) (int, error)//用于输出的接口type io.Writer interface &#123; Write(p []byte) (n int,err error)&#125;//内置的错误接口type error interface &#123; Error() string&#125;//下面的代码我们可以通过定制自己的输出对象，将每个字符转为大写字符后输出type UpperWriter struct &#123; io.Writer&#125;func (p *UpperWriter) Write(data []byte) (n int, err error) &#123; return p.Writer.Write(bytes.ToUpper(data))&#125;func main() &#123; fmt.Fprintln(&amp;UpperWriter&#123;os.Stdoout&#125;, "hello, world")&#125; Go语言中，对于基础类型（非接口类型）不支持隐式转换，我们无法将一个int类型的值直接赋给int64类型的变量，也无法将int类型的值赋值给底层是int类型的新定义命名类型的变量。 虚拟继承12345678type animal interface &#123; func hello() func run()&#125;type xxx struct &#123; animal //加入了接口，但是没有实现具体的方法，实现了虚拟继承&#125; Goroutine和系统线程线程每个系统级的线程都会有一个固定大小的栈（默认2MB），这个栈主要用来保存函数调用时的参数和局部变量。 固定了栈的大小导致了两个问题，一个是对于只需要很小的栈空间的线程，是一种浪费，另一个是对于少数需要巨大栈空间的线程存在栈溢出的风险。Goroutine解决了这个问题。 协程一个Goroutine会以一个很小的的栈启动（可能是2kb或4kb），当遇到深度递归导致当前栈空间不足时，Goroutine会根据需要动态的伸缩栈的大小，因为启动的代价很小，所以我们可以轻易的启动成千上万个Goroutine。 Go的运行时还包含了自己的调度器，这个调度器使用了一些技术手段，可以在n个操作系统上多工调度m个Goroutine。Go调度器的工作和内核的调度是相似的，但是这个调度器只关注单独的Go程序中的Goroutine。 Goroutine采用半抢占式的协作调度，只有在当前Goroutine发生阻塞时才会调度；同时发生在用户态，调度器会根据具体函数只保存必要的寄存器，切换的大家要比系统级线程低的多 原子操作原子操作是指并发编程中，最小且不可并行化的操作。 如果多个并发体对同一个共享资源进行的操作是原子的话，那么同一时刻最多只能有一个并发体对该资源进行操作。 一般情况下原子的操作都是通过互斥来保证的，如下代码 互斥锁实现原子操作123456789101112131415161718192021222324252627282930package mainimport ( "fmt" "sync")var total struct&#123; sync.Mutex value int&#125;func worker(wg *sync.WaitGroup) &#123; defer wg.Done() for i:=0; i&lt;100; i++ &#123; total.Lock() total.value += 1 total.Unlock() &#125;&#125;func main() &#123; var wg sync.WaitGroup wg.Add(2) go worker(&amp;wg) go worker(&amp;wg) wg.Wait() fmt.Println(total.value)&#125; 使用golang中自带的atomic123456789101112131415161718192021222324252627package mainimport ( "fmt" "sync" "sync/atomic")var total uint64func worker(wg *sync.WaitGroup) &#123; defer wg.Done() for i:=0; i&lt;100; i++ &#123; total = atomic.AddUint64(&amp;total, 1) &#125;&#125;func main() &#123; wg := &amp;sync.WaitGroup&#123;&#125; wg.Add(2) go worker(wg) go worker(wg) wg.Wait() fmt.Println(total)&#125; 利用atomic和互斥锁实现单例模式1234567891011121314151617181920212223242526272829303132package mainimport ( "sync" "sync/atomic")type singleton struct &#123;&#125;var ( instance *singleton initialized uint32 mu sync.Mutex)func Instance() *singleton&#123; if atomic.LoadUint32(&amp;initialized) == 1 &#123; return instance &#125; mu.Lock() defer mu.Unlock() if instance == nil &#123; defer atomic.StoreUint32(&amp;initialized, 1) instance = &amp;singleton&#123;&#125; &#125; return instance&#125; 利用golang内置库Once实现单例模式1234567891011var ( instance *singleton once sync.Once)func Instance() *singleton &#123; Once.Do(func() &#123; instance = &amp;singleton &#125;) return instance&#125; 并发模型 并发不是并行，并发更多关注的是程序设计层面，并发的程序完全可以顺序执行，只有在真正的多核cpu上才可能真正的同时运行 不要通过共享内存来通信，而用通信来共享内存在并发编程中，对共享资源的正确访问需要精确的控制，在目前绝大多数语言中，都是通过加锁等线程同步方案来解决这一问题，在go语言中将共享的值通过channel传递，在任意给定时刻，最好只有一个goroutine能够拥有该资源，数据竞争从设计层面就被杜绝了。 生产者消费者模型12345678910111213141516171819202122232425262728package mainimport ( "fmt" "time")func Producer(basic int,c chan int) &#123; res := basic*2 c &lt;- res&#125;func Consumer(c chan int) &#123; for v := range c &#123; fmt.Println(v) &#125; &#125;func main() &#123; c := make(chan int) go Producer(2, c) go Producer(3,c) go Consumer(c) time.Sleep(time.Second)&#125; 发布订阅模型123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124package mainimport ( "fmt" "strings" "sync" "time")type ( subscriber chan interface&#123;&#125; topicFunc func(v interface&#123;&#125;) bool)type Publisher struct &#123; m sync.Mutex //读写锁 buffer int //订阅队列的缓存大小 timeout time.Duration //发布超时时间 subscribers map[subscriber] topicFunc //订阅者信息&#125;// 构建一个发布者对象，可以设置发布超时时间和缓存队列的长度func NewPublisher(publishTimeout time.Duration, buffer int) *Publisher &#123; return &amp;Publisher&#123; buffer: buffer, timeout: publishTimeout, subscribers: make(map[subscriber]topicFunc), &#125;&#125;//添加一个订阅者，订阅全部主题func (p *Publisher) Subscribe() chan interface&#123;&#125;&#123; return p.SubscribeTopic(nil)&#125;// 添加一个订阅者，订阅过滤器筛选后的主题func (p *Publisher) SubscribeTopic(topic topicFunc) chan interface&#123;&#125; &#123; ch := make(chan interface&#123;&#125;, p.buffer) p.m.Lock() p.subscribers[ch] = topic p.m.Unlock() return ch&#125;// 退出订阅func (p *Publisher) Exit(sub chan interface&#123;&#125;) &#123; p.m.Lock() defer p.m.Unlock() delete(p.subscribers, sub) close(sub)&#125;// 发布一个主题func (p *Publisher) Publish(v interface&#123;&#125;) &#123; p.m.Lock() defer p.m.Unlock() var wg sync.WaitGroup for sub, topic := range p.subscribers &#123; wg.Add(1) go p.sendTopic(sub, topic, v, &amp;wg) &#125; wg.Wait()&#125;// 关闭发布者对象，同时关闭所有订阅者对象func (p *Publisher) Close() &#123; p.m.Lock() defer p.m.Unlock() for sub := range p.subscribers &#123; delete(p.subscribers, sub) close(sub) &#125;&#125;// 发送主题， 可以容忍一定超时func (p *Publisher) sendTopic( sub subscriber, topic topicFunc, v interface&#123;&#125;, wg *sync.WaitGroup, ) &#123; defer wg.Done() if topic != nil &amp;&amp; !topic(v) &#123; return &#125; select &#123; case sub &lt;- v: case &lt;-time.After(p.timeout): &#125;&#125;func main() &#123; p := NewPublisher(100 * time.Millisecond, 10) defer p.Close() all := p.Subscribe() golang := p.SubscribeTopic(func (v interface&#123;&#125;) bool &#123; if s, ok := v.(string); ok &#123; return strings.Contains(s, "golang") &#125; return false &#125;) p.Publish("hello, world") p.Publish("hello, golang") go func() &#123; for msg := range all &#123; fmt.Println("all:", msg) &#125; &#125;() go func() &#123; for msg := range golang &#123; fmt.Println("golang:", msg) &#125; &#125;() time.Sleep(3 * time.Second)&#125; Select基于select实现管道的超时判断123456select &#123; case v := &lt;- in : fmt.Println(v) case &lt;-time.After(time.Second): return //超时&#125; 基于select的default分支实现非阻塞的管道发送或接收操作123456select &#123; case v := &lt;-in : fmt.Println(v) default: //无数据&#125; 通过select来阻止main退出123func main() &#123; select&#123;&#125;&#125; 基于select来实现随机数123456789101112131415func main() &#123; ch := make(chan int) go func() &#123; for &#123; select &#123; case ch &lt;- 0: case ch &lt;- 1: &#125; &#125; &#125;() for v := range ch &#123; fmt.Println(v) &#125;&#125; 基于select实现goroutine的退出12345678910111213141516171819202122232425package mainimport ( "fmt" "time")func worker(close chan int) &#123; for &#123; select &#123; case &lt;- close: break default: fmt.Println(123) &#125; &#125;&#125;func main() &#123; c := make(chan int) go worker(c) time.Sleep(time.Second) c &lt;- 1&#125; 基于select实现goroutine退出 V2123456789101112131415161718192021222324252627package mainimport ( "fmt" "time")func worker(close chan int) &#123; for &#123; select &#123; case &lt;- close: break default: fmt.Println(123) &#125; &#125;&#125;func main() &#123; c := make(chan int) for i:=0; i&lt; 100; i++ &#123; go worker(c) &#125; time.Sleep(time.Second) close(c)&#125; 由于管道的接收和发送是一一对应的，如果要停止多个goroutine那么需要创建同样数量的管道，性能差，所以可以通过一个管道来实现广播的操作。 基于select实现goroutine退出 V312345678910111213141516171819202122232425262728293031323334package mainimport ( "fmt" "sync" "time")func worker(wg *sync.WaitGroup, close chan int) &#123; defer wg.Done() for &#123; select &#123; case &lt;- close: return default: fmt.Println(123) &#125; &#125;&#125;func main() &#123; c := make(chan int) wg := &amp;sync.WaitGroup&#123;&#125; for i:=0; i&lt; 100; i++ &#123; wg.Add(1) go worker(wg, c) &#125; time.Sleep(time.Second) close(c) wg.Wait()&#125; 当每个goroutine收到退出指令时，一般会进行一定的清理工作，但是退出清理的工作无法保证一定完成，因为main线程没有等待各个goroutine工作完成的机制，所以结合sync.WaitGroup增强代码的健壮性 Context1234567891011121314151617181920212223242526272829303132333435package mainimport ( "context" "fmt" "sync" "time")func worker(ct context.Context, wg *sync.WaitGroup) error&#123; defer wg.Done() for &#123; select &#123; default: fmt.Println(123) case &lt;-ct.Done(): return ct.Err() &#125; &#125;&#125;func main() &#123; wg := &amp;sync.WaitGroup&#123;&#125; ct, cancel := context.WithTimeout(context.Background(), time.Second) for i:=0; i&lt;100; i++ &#123; wg.Add(1) go worker(ct, wg) &#125; time.Sleep(time.Second) cancel() wg.Wait()&#125; 错误和异常错误处理策略123456789101112package mainimport "fmt"func main() &#123; defer func() &#123; if p := recover(); p != nil &#123; fmt.Printf("%v", p) &#125; &#125;() panic("test")&#125; 捕获异常不是最终目的，如果异常不可预测，直接输出异常信息是最好的处理方式。 RPCRPC基本示例服务器端123456789101112131415161718192021222324252627282930313233package mainimport ( "fmt" "net" "net/rpc")type HelloService struct &#123;&#125;func (this *HelloService) Hello(name string,reply *string) error &#123; *reply = "hello" + name return nil&#125;func main() &#123; rpc.RegisterName("HelloService", new(HelloService)) listener, err := net.Listen("tcp", ":6062") if err != nil &#123; panic(err) &#125; conn,err := listener.Accept() if err != nil &#123; panic(err) &#125; fmt.Printf("listening") rpc.ServeConn(conn)&#125; 客户端1234567891011121314151617181920package mainimport ( "fmt" "net/rpc")func main() &#123; conn,err := rpc.Dial("tcp",":6062") if err != nil &#123; panic(err) &#125; var reply string err = conn.Call("HelloService.Hello","world", &amp;reply) if err != nil &#123; panic(err) &#125; fmt.Printf("%v",reply)&#125; 深入了解RPC客户端rpc实现原理Call123456789/**通常我们在客户端调用rpc框架中的call方法进行同步阻塞调用该方法首先通过client.Go方法进行了一次异步调用,返回一个表名这次调用的Call结构体。然后等待Call结构体的Done**/func (client *Client) Call(serviceMethod string, args interface&#123;&#125;, reply interface&#123;&#125;) error &#123; call := &lt;-client.Go(serviceMethod, args, reply, make(chan *Call, 1)).Done return call.Error&#125; Go12345678910111213141516171819202122232425/**首先构造了一个表示当前调用的call变量然后通过client.send方法将call的完整参数发送到rpc框架，send方法是线程安全的当调用完成或者发生错误时，将调用call.done()方法**/func (client *Client) Go(serviceMethod string, args interface&#123;&#125;, reply interface&#123;&#125;, done chan *Call) *Call &#123; call := new(Call) call.ServiceMethod = serviceMethod call.Args = args call.Reply = reply if done == nil &#123; done = make(chan *Call, 10) // buffered. &#125; else &#123; // If caller passes done != nil, it must arrange that // done has enough buffer for the number of simultaneous // RPCs that will be using that channel. If the channel // is totally unbuffered, it's best not to run at all. if cap(done) == 0 &#123; log.Panic("rpc: done channel is unbuffered") &#125; &#125; call.Done = done client.send(call) return call&#125; Done123456789101112func (call *Call) done() &#123; select &#123; case call.Done &lt;- call: // ok default: // We don't want to block here. It is the caller's responsibility to make // sure the channel has enough buffer space. See comment in Go(). if debugLog &#123; log.Println("rpc: discarding Call reply due to insufficient Done chan capacity") &#125; &#125;&#125; Protobuf Protobuf作为接口规范的描述语言，可以作为设计安全的跨语言RPC接口的基础工具 grpc 如果从Protobuf的角度看，gRPC只不过是一个针对service接口生成代码的生成器 示例1234567891011syntax = &quot;proto3&quot;;package hello;message String &#123; string value = 1;&#125;service HelloService &#123; rpc Hello(String) returns (String);&#125; 运行 1protoc --proto_path=. --go_out=plugins=grpc:. hello.proto 生成 12345678910111213141516171819func RegisterHelloServiceServer(s *grpc.Server, srv HelloServiceServer) &#123; s.RegisterService(&amp;_HelloService_serviceDesc, srv)&#125;func NewHelloServiceClient(cc grpc.ClientConnInterface) HelloServiceClient &#123; return &amp;helloServiceClient&#123;cc&#125;&#125;// HelloServiceServer is the server API for HelloService service.type HelloServiceServer interface &#123; Hello(context.Context, *String) (*String, error)&#125;// HelloServiceClient is the client API for HelloService service.//// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.type HelloServiceClient interface &#123; Hello(ctx context.Context, in *String, opts ...grpc.CallOption) (*String, error)&#125; 重写HelloService服务端123456789101112131415161718192021222324252627282930package mainimport ( hello "code.yuhaos.com/studygo/grpc/protobuf" "context" "google.golang.org/grpc" "net")type HelloService struct &#123;&#125;func (p *HelloService) Hello(ctx context.Context, name *hello.String) (*hello.String, error) &#123; var ret hello.String ret.Value = "hello" + name.Value return &amp;ret, nil&#125;func main() &#123; grpcServer := grpc.NewServer() hello.RegisterHelloServiceServer(grpcServer, new(HelloService)) listener, err := net.Listen("tcp", ":1234") if err != nil &#123; panic(err) &#125; grpcServer.Serve(listener)&#125; 重写HelloService客户端123456789101112131415161718192021222324package mainimport ( hello "code.yuhaos.com/studygo/grpc/protobuf" "context" "fmt" "google.golang.org/grpc")func main() &#123; conn, err := grpc.Dial(":1234",grpc.WithInsecure()) if err != nil &#123; panic(err) &#125; defer conn.Close() client := hello.NewHelloServiceClient(conn) res, err := client.Hello(context.Background(), &amp;hello.String&#123;Value:"world"&#125;) if err != nil &#123; panic(err) &#125; fmt.Println(res.Value)&#125; gRPC流 RPC是远程调用，因此每次调用的函数参数和返回值不能太大，否则将严重影响每次调用的响应时间，因此传统的RPC方法调用对于上传和下载大数据量的场景并不合适，为此gRPC框架针对服务器和客户端分别提供了流特性 protobuf123456789101112syntax = &quot;proto3&quot;;package hello;message String &#123; string value = 1;&#125;service HelloService &#123; rpc Hello(String) returns (String); rpc Channel (stream String) returns (stream String);&#125; 123456789101112131415161718192021222324252627282930/**HelloSerivceServer和HelloServiceClient两个接口都添加了Channel方法的定义该方法可以用于客户端和服务端的双向通信**/type HelloServiceServer interface &#123; Hello(context.Context, *String) (*String, error) Channel(HelloService_ChannelServer) error&#125;type HelloServiceClient interface &#123; Hello(ctx context.Context, in *String, opts ...grpc.CallOption) (*String, error) Channel(ctx context.Context, opts ...grpc.CallOption) (HelloService_ChannelClient, error)&#125;/**HelloService_ChannelServer和HelloService_ChannelClient都为接口**/type HelloService_ChannelServer interface &#123; Send(*String) error Recv() (*String, error) grpc.ServerStream&#125;type HelloService_ChannelClient interface &#123; Send(*String) error Recv() (*String, error) grpc.ClientStream&#125; 基于流的Server12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package mainimport ( hello "code.yuhaos.com/studygo/grpc/protobuf" "context" "google.golang.org/grpc" "io" "net")type HelloService struct &#123;&#125;func (p *HelloService) Hello(ctx context.Context, name *hello.String) (*hello.String, error) &#123; var ret hello.String ret.Value = "hello" + name.Value return &amp;ret, nil&#125;func (p *HelloService) Channel(stream hello.HelloService_ChannelServer) error &#123; for &#123; args, err := stream.Recv() if err != nil &#123; if err == io.EOF &#123; return nil &#125; return err &#125; reply := &amp;hello.String&#123;Value:"Hello" + args.GetValue()&#125; err = stream.Send(reply) if err != nil &#123; return err &#125; &#125;&#125;func main() &#123; grpcServer := grpc.NewServer() hello.RegisterHelloServiceServer(grpcServer, new(HelloService)) listener, err := net.Listen("tcp", ":1234") if err != nil &#123; panic(err) &#125; grpcServer.Serve(listener)&#125; 基于流的client123456789101112131415161718192021222324252627282930313233343536373839404142434445package mainimport ( hello "code.yuhaos.com/studygo/grpc/protobuf" "context" "fmt" "google.golang.org/grpc" "io" "time")func main() &#123; conn, err := grpc.Dial(":1234",grpc.WithInsecure()) if err != nil &#123; panic(err) &#125; defer conn.Close() client := hello.NewHelloServiceClient(conn) stream, err := client.Channel(context.Background()) if err != nil &#123; panic(err) &#125; go func() &#123; for &#123; if err := stream.Send(&amp;hello.String&#123;Value:"hi"&#125;); err != nil &#123; panic(err) &#125; time.Sleep(time.Second) &#125; &#125;() for &#123; res, err := stream.Recv() if err != nil &#123; if err == io.EOF &#123; break &#125; panic(err) &#125; fmt.Println(res.GetValue()) &#125;&#125; 基于docker的pub/sub与grpc流实现发布订阅模型protobuf123456789101112syntax = &quot;proto3&quot;;package pub_sub_service;message String &#123; string value=1;&#125;service PubsubService &#123; rpc Publish(String) returns (String); rpc Subscribe(String) returns (stream String);&#125; service12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package mainimport ( pub_sub_service "code.yuhaos.com/studygo/grpc-pub-sub/protobuf" "context" "github.com/docker/docker/pkg/pubsub" "google.golang.org/grpc" "net" "strings" "time")type PubsubService struct &#123; pub *pubsub.Publisher&#125;func NewPubSubService() *PubsubService&#123; return &amp;PubsubService&#123; pub:pubsub.NewPublisher(100*time.Millisecond, 10), &#125;&#125;func (p *PubsubService) Publish(ctx context.Context, arg *pub_sub_service.String) (*pub_sub_service.String, error)&#123; p.pub.Publish(arg.GetValue()) return &amp;pub_sub_service.String&#123;&#125;, nil&#125;func (p *PubsubService) Subscribe(arg *pub_sub_service.String, stream pub_sub_service.PubsubService_SubscribeServer) error&#123; ch := p.pub.SubscribeTopic(func(v interface&#123;&#125;) bool &#123; if key, ok := v.(string); ok &#123; if strings.HasPrefix(key, arg.GetValue()) &#123; return true &#125; &#125; return false &#125;) for v := range ch &#123; if err := stream.Send(&amp;pub_sub_service.String&#123;Value:v.(string)&#125;); err != nil &#123; return err &#125; &#125; return nil&#125;func main() &#123; grpcServer := grpc.NewServer() pub_sub_service.RegisterPubsubServiceServer(grpcServer, NewPubSubService()) listener, err := net.Listen("tcp", ":1235") if err != nil &#123; panic(err) &#125; grpcServer.Serve(listener)&#125; client_pub123456789101112131415161718192021222324252627package mainimport ( pub_sub_service "code.yuhaos.com/studygo/grpc-pub-sub/protobuf" "context" "google.golang.org/grpc")func main() &#123; conn, err := grpc.Dial("localhost:1235", grpc.WithInsecure()) if err != nil &#123; panic(err) &#125; defer conn.Close() client := pub_sub_service.NewPubsubServiceClient(conn) _, err = client.Publish(context.Background(), &amp;pub_sub_service.String&#123;Value:"golang:hello go"&#125;) if err != nil &#123; panic(err) &#125; _, err = client.Publish(context.Background(), &amp;pub_sub_service.String&#123;Value:"php:hello php"&#125;) if err != nil &#123; panic(err) &#125;&#125; client_sub1234567891011121314151617181920212223242526272829303132333435package mainimport ( pub_sub_service "code.yuhaos.com/studygo/grpc-pub-sub/protobuf" "context" "fmt" "google.golang.org/grpc" "io")func main() &#123; conn, err := grpc.Dial(":1235", grpc.WithInsecure()) if err != nil &#123; panic(err) &#125; defer conn.Close() client := pub_sub_service.NewPubsubServiceClient(conn) stream, err := client.Subscribe(context.Background(), &amp;pub_sub_service.String&#123;Value:"go"&#125;) if err != nil &#123; panic(err) &#125; for &#123; reply, err := stream.Recv() if err != nil &#123; if err == io.EOF &#123; break &#125; fmt.Printf("err") continue &#125; fmt.Println("reply:%v", reply.GetValue()) &#125;&#125; GO-WEBhttprouter路由冲突1234567conflict:GET /user/info/:nameGET /user/:idno conflict:GET /user/info/:namePOST /user/:id 因为httprouter使用的是显示匹配，所以在设计路由时需要规避一些会导致路由冲突的情况 如果两个路由拥有一致的http方法和请求路径前缀，切在某个位置出现了A路由是wildcard(:id)参数，B路由是普通字符串那么就会发生路由冲突 对特殊情况进行定制123456789101112131415161718192021package mainimport ( "github.com/julienschmidt/httprouter" "net/http")func main() &#123; r := httprouter.New() r.NotFound = http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) &#123; w.Write([]byte("404")) &#125;) r.PanicHandler = func(writer http.ResponseWriter, request *http.Request, i interface&#123;&#125;) &#123; writer.Write([]byte("500")) &#125; http.ListenAndServe(":8081", r)&#125; 原理Httprouter和众多衍生router使用的数据结构被称为压缩字典树。 发生路由冲突的情况也是由于构建压缩字典树时造成的。 中间件1234567891011121314151617181920212223242526package mainimport ( "github.com/sirupsen/logrus" "net/http")func LogMiddleware(next http.Handler) http.Handler&#123; return http.HandlerFunc(func (w http.ResponseWriter, r *http.Request)&#123; logrus.Println("test") next.ServeHTTP(w, r) &#125;)&#125;func Hello(w http.ResponseWriter, r *http.Request) &#123; w.Write([]byte("hello"))&#125;func main() &#123; http.Handle("/test", LogMiddleware(http.HandlerFunc(Hello))) http.ListenAndServe(":8081", nil)&#125; 中间件的原理1234567891011//中间件的原理在于http.handle方法中需要传入Handler参数//handler为一个接口，既只要实现了ServeHTTP方法的即为Handlertype Handler interface &#123; ServeHTTP(ResponseWriter, *Request)&#125;//HandlerFunc可以将普通的方法强转为Handler类型type HandlerFunc func(ResponseWriter, *Request)func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request) &#123; f(w, r)&#125; 更优雅的使用中间件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package mainimport ( "github.com/sirupsen/logrus" "net/http")type middleware func(http.Handler) http.Handlertype Router struct &#123; middlewareChain [] middleware mux map[string] http.Handler&#125;func NewRouter() *Router &#123; return &amp;Router&#123; middlewareChain:[]middleware&#123;&#125;, mux: make(map[string] http.Handler), &#125;&#125;func (r *Router) Use(m middleware) &#123; r.middlewareChain = append(r.middlewareChain, m)&#125;func (r *Router) Add(route string, h http.Handler) &#123; var mergeHandler = h for i := len(r.middlewareChain)-1; i&gt;=0; i-- &#123; mergeHandler = r.middlewareChain[i](mergeHandler) &#125; r.mux[route] = mergeHandler&#125;func (r *Router) ServeHTTP(writer http.ResponseWriter, request *http.Request) &#123;&#125;func LogMiddleware(next http.Handler) http.Handler&#123; return http.HandlerFunc(func (w http.ResponseWriter, r *http.Request)&#123; logrus.Println("test") next.ServeHTTP(w, r) &#125;)&#125;func Hello(w http.ResponseWriter, r *http.Request) &#123; w.Write([]byte("hello"))&#125;func main() &#123; r := NewRouter() r.Use(LogMiddleware) r.Add("/test", http.HandlerFunc(Hello)) http.ListenAndServe(":8081", r)&#125; 服务流量限制问题有些程序偏网络IO瓶颈，例如CDN服务，Proxy服务 有些程序偏CPU/GPU瓶颈，例如登录校验服务，图像处理服务 有些程序偏磁盘，例如存储系统，数据库 对于IO/Network瓶颈类的程序，其表现是网课/磁盘IO会先于CPU打满，这种情况即使优化CPU的使用也无法提高整个系统的吞吐量，只有提高磁盘的读写速度，增加内存大小，提升网卡带宽来提升整体性能 漏桶限流 我们有一个，每过一段时间，向外漏一滴水，如果你接到了这滴水，那么就可以继续服务请求，否则需要等待下一滴水 令牌桶 匀速向桶中添加令牌，服务请求时需要从桶中获取令牌，令牌的数目可以按照需要消耗的资源进行相应的调整，如果没有令牌，可以选择等待或者放弃。该模型支持并发。 1234567891011121314151617181920212223242526272829303132/**令牌桶模拟**/package mainimport ( "fmt" "time")func main() &#123; var fillInterval = time.Millisecond * 10 var capacity = 100 var tokenBucket = make(chan struct&#123;&#125;, capacity) fillToken := func() &#123; ticker := time.NewTicker(fillInterval) for &#123; select &#123; case &lt;-ticker.C: select &#123; case tokenBucket &lt;- struct&#123;&#125;&#123;&#125;: default: &#125; fmt.Println("current token cnt:", len(tokenBucket), time.Now()) &#125; &#125; &#125; go fillToken() time.Sleep(time.Hour)&#125; 123456789101112131415161718/**模拟取令牌**/TakeAvailable := func(block bool) bool &#123; var takenResult bool if block &#123; select &#123; case &lt;-tokenBucket: takenResult = true &#125; &#125; else &#123; select &#123; case &lt;- tokenBucket: takenResult = true default: takenResult = false &#125; &#125; 上述方法是一般令牌桶的实现，下面是优化算法 12345/**思考一下，令牌桶每隔一段固定时间向桶中放令牌，我们记下上一次放令牌的时间为t1和当时的令牌数为k1,放令牌的间隔时间为ti，每次向桶中放x个令牌，令牌容量为cap。现在如果有人来获取令牌时间为t2，在t2时刻应该存在的令牌为多少呢？**/cur = k1 + ((t2-t1)/ti)*xcur = cur &gt; cap ? cap : cur 通过这种方式，只需要在取令牌的时候去获取令牌数量，在得到正确的令牌数之后，再进行实际的take即可。 分布式系统分布式ID-雪花算法 首先确定数值是64位，将其划分为4个部分，不含开头的第一个bit，这个bit是符号位 第一部分，用41位来代表收到请求的时间戳，单位为毫秒 第二部分，用5位来表示数据中心id 第三部分，用5位来表示机器实例id 第四部分，用12位的循环自增id 这样一台机器，同一毫秒可以生产 2 ^ 12 = 4096条消息，一秒409.6万条 数据中心加上实例id共10位，可以支持我们每个数据中心部署32台机器，所有数据中心1024台实例 分布式锁redis setnx基于zooKeeper12345678910111213141516func main() &#123; c, _, err := zk.Connect([]string&#123;"127.0.0.1"&#125;, time.Second) if err != nil &#123; panic(err) &#125; l := zk.NewLock(c, "/lock", zk.WorldACL(zk.PermAll)) err = l.Lock() if err != nil &#123; panic(err) &#125; //lock succ l.Unlock() //unlock succ&#125; 基于zooKeeper的锁与基于redis的锁的不同之处在于Lock成功之前会一直阻塞 该种方式的原理是基于临时的Sequence节点和Watch API。 比如使用了/lock节点，Lock会在该节点下的节点列表中插入自己的值，只要节点下的子节点发生变化，就会通知所有watch该节点的程序。这时候程序会检查当前节点下最小的子节点的id是否与自己的一致。如果一致说明加锁成功了。 这种分布式的阻塞锁比较适合分布式的任务调度场景，但不适合高频次的持锁时间短的抢锁场景。 Google的Chubby论文里的阐述，基于强一致协议的锁适用于粗粒度的加锁操作。这里的粗粒度指锁的占用时间长。 基于etcd延时任务系统时间堆小顶堆小顶堆就是一种特殊的二叉树，对于定时器来讲，如果堆顶的元素比当前时间还大，说明堆内的所有元素都比当前时间打 四叉堆Go内置的定时器利用了四叉堆 时间轮用时间轮来实现定时器时，我们需要定义每一个格子的刻度，中心有秒针顺时针转动。每转动到一个刻度时，我们就需要去查看该刻度挂载的任务列表是否有已到期的任务。 任务分发每一个实例，每个小时就去数据库里把下一个小时需要处理的任务捞出来。 可以通过： 将任务触发的信息封装为一条消息，发送到消息队列，由用户对消息队列进行监听。 对用户预先配置的回调函数进行调用。 数据再平衡当一台实例出现故障时，我们可以通过类似es的方式将数据同步到副本节点以保证数据再平衡。 负载均衡基于洗牌算法的负载均衡 设计y一个大小和节点数组一致的索引素组，每次新的请求来的时候，我们对索引数组洗牌，然后取第一个元素作为选中的服务节点，如果请求失败，选择下一个节点重试。 算法11234567891011121314var endpoints = []string &#123; "xxx.xxx.xxx.x:1", "xxx.xxx.xxx.x:2", "xxx.xxx.xxx.x:3", "xxx.xxx.xxx.x:4",&#125;func shuffle(slice []int) &#123; for i:=0; i&lt;len(slice); i++ &#123; a := rand.Intn(len(slice)) b := rand.Intn(len(slice)) slice[a], slice[b] = slice[b], slice[a] &#125;&#125; 算法2（更均衡）1234567func shuffle(indexs []int) &#123; for i:=len(indexs); i&gt;0; i-- &#123; lastIdx := i-1 idx := rand.Int(i) indexs[lastIdx], indexs[idx] = indexs[idx], indexs[lastIdx] &#125;&#125; 算法2简化1234func shuffle(n int) []int &#123; b := rand.Perm(n) return b&#125; 分布式配置管理基于etcd实现优点开箱即用 缺点不利于管理，无法承载高qps Go语言中使用时的坑可变参数是空接口类型当参数的可变参数是空接口类型时，传入空参数的切片时需要注意参数展开的问题 12345func main() &#123; var a = []interface&#123;&#125;&#123;1,2,3&#125; fmt.Println(a) // [1,2,3] fmt.Println(a...) // 1 2 3&#125; 数组是值传递在函数调用的过程中，数组是值传递 1234567891011func main() &#123; x := [3]int&#123;1,2,3&#125; func (arr [3]int) &#123; for i:=0; i&lt;len(arr); i++ &#123; arr[i] = arr[i]*2 &#125; &#125;(x) fmt.Println(x) //1 2 3&#125; map遍历是顺序不固定的map是一种hash表实现，每次遍历的顺序都可能不一样 recover必须在defer函数中运行123456func main() &#123; defer func () &#123; recover() &#125;() panic("recover test")&#125; 独占cpu导致其他的goroutine饿死Goroutine是协作式抢占调度，Goroutine本身不会主动放弃CPU: 1234567891011func main() &#123; runtime.GOMAXPROCS(1) go func() &#123; for i:=0; i&lt;10; i++ &#123; fmt.Println(i) &#125; &#125;() for &#123;&#125; //占用cpu&#125; 解决方案1：利用runtime.Gosched() 12345678910111213func main() &#123; runtime.GOMAXPROCS(1) go func() &#123; for i:=0; i&lt;10; i++ &#123; fmt.Println(i) &#125; &#125;() for &#123; runtime.Gosched() &#125;&#125; 解决方案2: 通过阻塞方式 123456789101112func main() &#123; runtime.GOMAXPROCS(1) go func() &#123; for i:=0; i&lt;10; i++ &#123; fmt.Println(i) &#125; os.Exit(0) &#125;() select&#123;&#125;&#125; 不同的goroutine之间不满足顺序一致性内存模型1234567891011121314151617181920package mainimport "fmt"var msg stringvar done boolfunc setup() &#123; msg = "hello" done = true&#125;func main() &#123; go setup() for !done &#123; &#125; fmt.Println(msg)&#125; 在该程序中，对于main来说msg=”hello”和done=true的执行顺序是不确定的，所以可能无法输出hello，做以下修改保证了一致性 123456789101112131415161718package mainimport "fmt"var msg stringvar done = make(chan bool)func setup() &#123; msg = "hello" done &lt;- true&#125;func main() &#123; go setup() &lt;-done fmt.Println(msg)&#125; 闭包错误引用同一个变量12345678func main() &#123; for i:=0; i&lt;5; i++ &#123; defer func() &#123; println(i) &#125;() &#125;&#125;//5 5 5 5 5 修正后 12345678//每轮迭代中生成一个局部变量通过参数传入func main() &#123; for i:=0; i&lt;5; i++ &#123; defer func() &#123; println(i) &#125;(i) &#125;&#125; 在循环内部执行defer语句defer在循环退出时才能执行，在for执行defer会导致资源延迟释放 123456789func main() &#123; for i:=0; i&lt;5; i++ &#123; f, err := os.Open('/path/to/file') if err != nil &#123; log.Fatal(err) &#125; defer f.Close() &#125;&#125; 可以通过在for中构造一个局部函数，在局部函数内部defer 1234567891011func main() &#123; for i:=0; i&lt;5; i++ &#123; func() &#123; f, err := os.Open('/path/to/file') if err != nil &#123; log.Fatal(err) &#125; defer f.Close() &#125;() &#125;&#125; 切片会导致整个底层数组被锁定切片会导致整个底层数组被锁定，底层数组无法释放内存。 1234567891011func main() &#123; headerMap := make(map[string][]byte) for i:=0; i&lt;5; i++ &#123; name := "/path/to/file" data, err := ioutil.ReadFile(name) if err != nil &#123; log.Fatal(err) &#125; headerMap[name] = data[:1] //导致底层数组被锁定 &#125;&#125; 优化，将结果克隆一份 1234567891011func main() &#123;headerMap := make(map[string][]byte) for i:=0; i&lt;5; i++ &#123; name := "/path/to/file" data, err := ioutil.ReadFile(name) if err != nil &#123; log.Fatal(err) &#125; headerMap[name] = append([]byte&#123;&#125;, data[:1]) &#125;&#125;]]></content>
      <tags>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2020读书计划]]></title>
    <url>%2F2020%2F01%2F01%2F2020%E8%AF%BB%E4%B9%A6%E8%AE%A1%E5%88%92%2F</url>
    <content type="text"><![CDATA[专业 GO语言核心编程 趣谈网络协议 高性能MySQL Kafka权威指南 Redis设计与实现 数据结构与算法分析 操作系统导论 其他 恶意 浪潮之巅 人性的弱点 软技能 : 代码之外的生存指南 重构 : 改善既有代码的设计 海边的卡夫卡]]></content>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OPCache]]></title>
    <url>%2F2019%2F12%2F21%2FOPCache%2F</url>
    <content type="text"><![CDATA[PHP-FPM+Nginx工作机制 启动服务 启动PHP-FPM，PHP-FPM支持两种通信模型：TCP Socket和Unix Scoket PHP-FPM启动两种类型的进程：Master和Worker，前者负责监控端口，分配任务，管理Worker；后者负责编译执行PHP脚本，是PHP的cgi程序。 启动Nginx,载入ngx_http_fastcgi_module模块，初始化FastCGI执行环境。实现FastCGI协议请求代理 Request=====&gt;Nginx Nginx接收请求，并基于location配置，选择一个合适的Handler Nginx=====&gt;PHP-FPM Nginx把请求翻译成fastcgi请求，通过TCP socket/Unix Socket发送请求给PHP-FPM的Master进程 PHP-FPM Master =====&gt; Worker PHP-FPM master进程接收到请求 分配Worker进程执行PHP脚本，如果没有空闲的Worker，返回502错误 Worker（php-cgi）进程执行PHP脚本，如果超时，返回504错误 处理结束，返回结果. PHP-FPM Worker =====&gt; Master =====&gt; Nginx PHP-FPM Worker进程返回处理结果，并关闭连接，等待下一个请求 PHP-FPM Master通过Socket返回处理结果 Nginx Handler顺序将每一个响应buffer响应给客户端 PHP脚本解释执行的机制 php初始化执行环节，启动Zend引擎，加载注册的扩展模块 初始化后读取脚本文件，Zend引擎对脚本文件进行此法分析（lex），语法分析（bison），生成语法树 Zend引擎编译语法树，生成opcode zend引擎执行opcode返回执行结果 在php-cli模式下，每次执行脚本，四个步骤都会一次执行一遍。 在php-fpm模式下，步骤1在php-fpm启动时执行一次，步骤2-4每个请求都要执行一遍，是对系统资源的极大浪费 可以通过OPCache配合APCu来进行优化 OPCache原理OPCache的缓存机制主要是：将编译好的操作码放入共享内存，提供给其他进程访问。 共享内存互斥锁一个单位时间内，只允许一个进程执行写操作，允许多个进程执行读操作，写操作同时不阻止读操作 OPCode缓存OPCache会缓存OPCode以下内容： PHP脚本涉及到的函数 PHP脚本中定义的Class PHP脚本文件路径 PHP脚本OPArray PHP脚本自身结构/内容 Interned String缓存Interned String用于优化PHP对字符串的存储和处理 包括 变量名称、类名、方法名、字符串、注释等 OPCache更新策略到期数据设位置Wasted，达到设定值，清空缓存，重建缓存 OPCache在创建缓存时并不会阻止其他进程读取，这会导致大量进程反复新建缓存。所以不要设置OPCache过期时间。 可以通过代码预热，比如使用脚本批量调PHP访问URL或者使用OPCache暴露的API如opcache_compile_file()进行编译缓存 配置建议123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596zend_extension=opcache.so; Zend Optimizer + 的开关, 关闭时代码不再优化.opcache.enable=1; Determines if Zend OPCache is enabled for the CLI version of PHPopcache.enable_cli=1; Zend Optimizer + 共享内存的大小, 总共能够存储多少预编译的 PHP 代码(单位:MB); 推荐 128opcache.memory_consumption=64; Zend Optimizer + 暂存池中字符串的占内存总量.(单位:MB); 推荐 8opcache.interned_strings_buffer=4; 最大缓存的文件数目 200 到 100000 之间; 推荐 4000opcache.max_accelerated_files=2000; 内存“浪费”达到此值对应的百分比,就会发起一个重启调度.opcache.max_wasted_percentage=5; 开启这条指令, Zend Optimizer + 会自动将当前工作目录的名字追加到脚本键上,; 以此消除同名文件间的键值命名冲突.关闭这条指令会提升性能,; 但是会对已存在的应用造成破坏.opcache.use_cwd=0; 开启文件时间戳验证 opcache.validate_timestamps=1; 2s检查一次文件更新 注意:0是一直检查不是关闭; 推荐 60opcache.revalidate_freq=2; 允许或禁止在 include_path 中进行文件搜索的优化;opcache.revalidate_path=0; 是否保存文件/函数的注释 如果apigen、Doctrine、 ZF2、 PHPUnit需要文件注释; 推荐 0opcache.save_comments=1; 是否加载文件/函数的注释;opcache.load_comments=1; 打开快速关闭, 打开这个在PHP Request Shutdown的时候会收内存的速度会提高; 推荐 1opcache.fast_shutdown=1;允许覆盖文件存在（file_exists等）的优化特性。;opcache.enable_file_override=0; 定义启动多少个优化过程;opcache.optimization_level=0xffffffff; 启用此Hack可以暂时性的解决”can’t redeclare class”错误.;opcache.inherited_hack=1; 启用此Hack可以暂时性的解决”can’t redeclare class”错误.;opcache.dups_fix=0; 设置不缓存的黑名单; 不缓存指定目录下cache_开头的PHP文件. /png/www/example.com/public_html/cache/cache_ ;opcache.blacklist_filename=; 通过文件大小屏除大文件的缓存.默认情况下所有的文件都会被缓存.;opcache.max_file_size=0; 每 N 次请求检查一次缓存校验.默认值0表示检查被禁用了.; 由于计算校验值有损性能,这个指令应当紧紧在开发调试的时候开启.;opcache.consistency_checks=0; 从缓存不被访问后,等待多久后(单位为秒)调度重启;opcache.force_restart_timeout=180; 错误日志文件名.留空表示使用标准错误输出(stderr).;opcache.error_log=; 将错误信息写入到服务器(Apache等)日志;opcache.log_verbosity_level=1; 内存共享的首选后台.留空则是让系统选择.;opcache.preferred_memory_model=; 防止共享内存在脚本执行期间被意外写入, 仅用于内部调试.;opcache.protect_memory=0]]></content>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP7新特性]]></title>
    <url>%2F2019%2F12%2F21%2FPHP7%E6%96%B0%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[性能提升 Zval改变 PHP中变量的载体是Zval PHP5中的Zval，内存占据24个字节 PHP7中的Zval，内存占据16个字节， zend_string的改变 PHP中字符串的载体是zend_string结构体 PHP7的zend_string结构体最后一个成员变量采用了char数组，而不是使用char*，可以降低CPU的cache miss 123456struct _zend_string &#123; zend_refcounted_h gc; /* 垃圾回收结构体 */ zend_ulong h; /* 字符串哈希值 */ size_t len; /* 字符串长度 */ char val[1]; /* 字符串内容 */&#125;; 数组变化 PHP5的数组是由HashTable实现的，PHP7的数组由Zend Array实现 Zend Array 将整块的数组元素和hash映射表全部连接在一起，被分配在同一块内存内 list 修改 12list($array[], $array[], $array[]) = [1, 2, 3];var_dump($array); foreach修改 foreach循环对数组内部指针不再起作用 12345$array = [0, 1, 2];foreach ($array as &amp;$val) &#123; var_dump(current($array));&#125; PHP7運行的結果會打印三次int(0)，也就是説數組的內部指針併沒有改變。 之前運行的結果會打印int(1), int(2)和bool(false) 按照值进行循环的时候，foreach是对该数组的拷贝操作 123456$array = [0, 1, 2];$ref =&amp; $array; // Necessary to trigger the old behaviorforeach ($array as $val) &#123; var_dump($val); unset($array[1]);&#125; 上麵的代碼雖然在循環中把數組的第二箇元素unset掉，但PHP7還是會把三箇元素打印齣來：(0 1 2) 之前老版本的PHP會把1跳過，隻打印(0 2). 按照引用进行循环的时候，对数组的修改会影响循环。 12345$array = [0];foreach ($array as &amp;$val) &#123; var_dump($val); $array[1] = 1;&#125; 上麵的代碼中追加的元素也會蔘與循環，這樣PHP7會打印”int(0) int(1)”，老版本隻會打印”int(0)”。 错误处理机制修改 新增Error异常类，与Exception都实现了同一个接口Throwable 123456&lt;?phptry &#123; say();&#125; catch(\Error $e) &#123; var_dump($-&gt;getMessage());&#125; 新增OPCache二级缓存 123456;配置二级缓存目录并启用二级缓存，启用二级缓存可以在SHM内存满了，服务器重启或者重置SHM的时候提高性能opcache.file_cache = '';启用或禁用在共享内存中的opcode缓存opcache.file_cache_only = true;当从文件缓存中加载脚本的时候，是否对文件校验和进行验证opcache.file_cache_consistency_checks = true]]></content>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP引用变量]]></title>
    <url>%2F2019%2F11%2F23%2FPHP%E5%BC%95%E7%94%A8%E5%8F%98%E9%87%8F%2F</url>
    <content type="text"><![CDATA[COW机制 详解参考 https://www.cnblogs.com/yclu/p/4712347.html 123456789&lt;?php$a = range(1,100000);var_dump(memory_get_usage()); //为变量a开辟一块内存空间$b = $a;var_dump(memory_get_usage()); //变量b指向变量a所在内存空间，不开辟新的内存空间$a = range(1, 100000); //变量a指向一块新的内存空间var_dump(memory_get_usage()); cow机制底层实现剖析1234567891011$a = range(0,3);xdebug_debug_zval('a');$b = $a;xdebug_debug_zval('a');$a = range(0,3);xdebug_debug_zval('a');res:a: (refcount=1, is_ref=0)=array (0 =&gt; (refcount=0, is_ref=0)=0, 1 =&gt; (refcount=0, is_ref=0)=1, 2 =&gt; (refcount=0, is_ref=0)=2, 3 =&gt; (refcount=0, is_ref=0)=3)a: (refcount=2, is_ref=0)=array (0 =&gt; (refcount=0, is_ref=0)=0, 1 =&gt; (refcount=0, is_ref=0)=1, 2 =&gt; (refcount=0, is_ref=0)=2, 3 =&gt; (refcount=0, is_ref=0)=3)a: (refcount=1, is_ref=0)=array (0 =&gt; (refcount=0, is_ref=0)=0, 1 =&gt; (refcount=0, is_ref=0)=1, 2 =&gt; (refcount=0, is_ref=0)=2, 3 =&gt; (refcount=0, is_ref=0)=3) 引用变量时，始终指向一块内存空间，底层refcount+1 1234567891011&lt;?php$a = range(0,3);xdebug_debug_zval('a');$b = &amp;$a;xdebug_debug_zval('a');$a = range(0,3);xdebug_debug_zval('a');a: (refcount=1, is_ref=0)=array (0 =&gt; (refcount=0, is_ref=0)=0, 1 =&gt; (refcount=0, is_ref=0)=1, 2 =&gt; (refcount=0, is_ref=0)=2, 3 =&gt; (refcount=0, is_ref=0)=3)a: (refcount=2, is_ref=1)=array (0 =&gt; (refcount=0, is_ref=0)=0, 1 =&gt; (refcount=0, is_ref=0)=1, 2 =&gt; (refcount=0, is_ref=0)=2, 3 =&gt; (refcount=0, is_ref=0)=3)a: (refcount=2, is_ref=1)=array (0 =&gt; (refcount=0, is_ref=0)=0, 1 =&gt; (refcount=0, is_ref=0)=1, 2 =&gt; (refcount=0, is_ref=0)=2, 3 =&gt; (refcount=0, is_ref=0)=3)e PHP对象赋值默认引用赋值1234567891011&lt;?phpclass person &#123; public $name;&#125;$p1 = new person;xdebug_debug_zval('p1');$p2 = $p1;xdebug_debug_zval('p1');$p2-&gt;name = 'zhangsan';xdebug_debug_zval('p1'); unset不会释放内存空间12345&lt;?php$a = 1;$b = &amp;$a;unset($b);echo $a; 经典案例1234567891011121314151617181920212223&lt;?php$arr = ['a','b','c'];foreach ($arr as $key =&gt; $value) &#123; $value = &amp;$arr[$key]; var_dump($arr);&#125;/*v-&gt;av-&gt;&amp;$arr[0]a,b,cv-&gt;b$arr[0]-&gt;bv-&gt;$arr[1]b,b,cv-&gt;c$arr[1]-&gt;cv-&gt;$arrr[2]b,c,c*/%]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F10%2F30%2FPHP-DOCKERFILE%2F</url>
    <content type="text"><![CDATA[PHP DOCKERFILE123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596FROM php:7.2-fpmRUN apt-get update -y &amp;&amp; \ apt-get install -y --no-install-recommends \ curl \ wget \ zip \ unzip \ vim \ git \ locales \ procops \ libz-dev \ libpq-dev \ libjpeg-dev \ libpng-dev \ libfreetype6-dev \ libssl-dev \ libmcrypt-dev \ libmemcached-dev \ libtool \ libicu-dev \ libxml2 \ libxml2-dev \ libgmp3-dev \ libevent-dev \ libzip-dev \ libb1g-dev \ libldap2-dev \ libbz2-dev \ libjpeg62-turbo-dev \ libtidy-dev \ libsqlite3-dev \ libsqlite3-0 \ tmux \ kychain \ supervisor \ &amp;&amp; mkdir -p /etc/supervisord.d/log \ &amp;&amp; mkdir -p /etc/supervisord.d/conf \ &amp;&amp; rm -rf /var/lib/apt/lists/*RUN wget --no-check-certificate https://gitee.com/oschina/hiredis/repository/archive/v0.13.3.zip -O hiredis.zip \ &amp;&amp; mkdir -p hiredis \ &amp;&amp; unzip hiredis.zip \ &amp;&amp; rm hiredis.zip \ &amp;&amp; ( \ cd hiredis \ &amp;&amp; make -j$(nproc) \ &amp;&amp; make install \ &amp;&amp; ldconfig\ ) &amp;&amp; rm -r hiredisRUN pecl channel-update pecl.php.net \ --with-jpeg-dir=/usr/lib \ --with-freetype-dir=/usr/include/freetype2 \ --with-zlib-dir=/usr \ &amp;&amp; docker-php-ext-configure ldap --with-libdir=lib/x86_64-linux-gnu/ \ &amp;&amp; docker-php-ext-install -j$(nproc) dba bz2 calendar ldap zip json tidy xml pdo_sqlite bcmath mysqli pdo_mysql gd sockets pcntl intl soap gmp \ &amp;&amp; pecl install msgpack \ &amp;&amp; docker-php-ext-enable msgpack \ &amp;&amp; pecl install seaslog \ &amp;&amp; docker-php-ext-enable seaslog \ &amp;&amp; pecl install redis \ &amp;&amp; docker-php-ext-enable redis \ &amp;&amp; pecl install inotify \ &amp;&amp; docker-php-ext-enable inotify \ &amp;&amp; pecl install grpc \ &amp;&amp; docker-php-ext-enable grpc \ &amp;&amp; pecl clear-cacheRUN wget --no-check-certificate https://gitee.com/swoole/swoole/repository/archive/v$&#123;SWOOLE_VERSION&#125;.zip -O swoole.zip \ &amp;&amp; mkdir -p swoole \ &amp;&amp; unzip swoole.zip \ &amp;&amp; rm swoole.zip \ &amp;&amp; ( \ cd swoole \ &amp;&amp; phize \ &amp;&amp; ./configure --enable-async-redis --enable-mysqlnd --enable-openssl \ &amp;&amp; make -j$(nproc) \ &amp;&amp; make install \ ) \ &amp;&amp; rm -r swoole \ &amp;&amp; docker-php-ext-enable swooleRUN curl -sS https://install.phpcomposer.com/installer | php \ &amp;&amp; mv composer.phar /usr/local/bin/composer \ &amp;&amp; composer self-update --clean-backups\ &amp;&amp; composer config -g repo.packagist composer https://packagist.laravel-china.orgCOPY supervisord.conf /etc/supervisord.confRUN chown -R www-data:www-data /var/log/www &amp;&amp; chown -R www-data:www-data /var/wwwEXPOSE 9000 5200ENTRYPOINT ["/usr/bin/supervisord","-n","-c","/etc/supervisord.conf"]]]></content>
  </entry>
  <entry>
    <title><![CDATA[PSR]]></title>
    <url>%2F2019%2F07%2F03%2FPSR%2F</url>
    <content type="text"><![CDATA[PSR是PHP Standards Recommendation的简称，是PHP-FIG制定的规范 PSR-1基本的代码风格 PHP标签 必须把PHP代码放在&lt;?php ?&gt;或&lt;?= ?&gt;标签中，不得使用其他标签语法编码 所有PHP文件都必须使用UTF-8字符集编码目的 一个PHP文件可以定义符号（类，性状，函数，常量等），或者执行有副作用的操作（生成结果，处理数据），但是不能同时做这两件事自动加载 PHP命名空间和类必须遵守PSR-4自动加载的标准类的名称 PHP类的名称必须使用驼峰式（CamelCase）常量的名称 PHP的创两必须全部使用大写，如果需要，可以用下划线把单词分开方法的名称 PHP的名称必须使用首字母小写的驼峰(camelCase) PSR-2严格的代码风格 贯彻PSR-1 使用PSR-2代码风格首先要贯彻PSR-1缩进 PSR-2要求使用4个空格缩进文件和代码行 PHP文件必须使用Unix风格的换行符，最后要有一个空行，而且不能使用PHP关闭标签?&gt;。每行代码不能超过80个字符，最多不能超过120个字符。每行末尾不能有空格关键字 PHP关键字都应该使用小写字母命名空间 每个命名空间声明行后都必须跟一个空行 在一系列use声明语句后要加一个空行类 类定义体的起始括号应该在类名之后新起一行写，类定义体的结束符号必须在定义体之后新起一行写 extends和implements关键字必须和类名写在同一行方法 方法定义体的起始括号应该在方法名之后新起一行写，方法定义体的结束符号必须在定义体之后新起一行写 方法的参数，起始的圆括号后面没有空格，结束圆括号之前也没有空格，方法的每个参数（除了最后一个）后面有一个逗号和空格 123public function hello($name = 'world', $who='xiaoming')&#123;&#125; 可见性 可见性由public，private和protected指定。 abstract和final必须放在可见性关键词之前 staic必须放在可见性关键词之后 123456class Test&#123; public $name; abstract $test; private statice $test;&#125; 控制结构 所有的控制结构关键词后面都要跟一个空格，控制解构的关键字包括：if，elseif，else，switch，case，while，do while，for，foreach，try，catch 如果控制结构关键词后面有一对括号，起始圆括号后面不能有空格，结束圆括号前面不能有空格。 控制结构后面的起始括号应该和控制关键字写在同一行。控制关键字后面的结束括号必须单独写在一行。 PSR-3日志记录器接口 符合PSR-3推荐规范的PHP日志记录器组件，必须包含一个实现Psr\Log\LoggerInter-face接口的PHP类,规定要实现九个方法 123456789101112131415&lt;?phpnamespace Psr\Log;interface LoggerInterface&#123; public function emergency($message,array $context = array()); public function alert($message,array $context = array()); public function critical($message,array $context = array()); public function error($message,array $context = array()); public function warning($message,array $context = array()); public function notice($message,array $context = array()); public function info($message,array $context = array()); public function debug($message,array $context = array()); public function log($message,array $context = array());&#125; 每个方法对应RFC 5424协议的一个日志级别，而且都接受两个参数，第一个参数$message必须是一个字符串，或者是一个有_toString()方法的对象。第二个参数是可选的，这是一个数组提供用于替换第一个参数中占位标记的值。常用的日志组件：monolog/monolog PSR-4自动加载 PSR-4描述的策略用于在运行时查找并加载PHP类，接口和性状。PSR-4推荐规范不要求来改变代码的实现方式，只建议如何使用文件系统目录结构和PHP命名空间组织代码。PSR-4自动加载器策略依赖PHP命名空间和文件系统目录结构查找并加载PHP类、接口和性状。PSR-4的精髓是把命名空间的前缀和文件系统中的目录对应起来。 12345678910111213spl_autoload_register(function ($class) &#123; $prefix = 'FOO\\Bar\\'; $baseDir = __DIR__ . '/src/'; $len = strlen($prefix); if (strncmp($prefix, $class, $len) !== 0) &#123; return; &#125; $relativeClass = substr($class,$len); $file = $baseDir . str_replace('\\','/',$relativeClass) . '.php'; if (file_exists($file)) &#123; require $file; &#125;&#125;);]]></content>
      <categories>
        <category>PHP</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[HTTP常用知识点]]></title>
    <url>%2F2019%2F07%2F01%2FHTTP%E5%B8%B8%E7%94%A8%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[##三次握手HTTP是基于TCP协议基础上的，TCP是传输层，HTTP是应用层TCP在连接时有三次握手第一次握手，首先客户端向服务器端发出一次请求，发送一个随机码第二次握手，服务器接受到随机码收，将随机码+1返回，并返回确认信息(ACK=1)和自己的随机码第三次握手，客户端接收到确认信息，并验证随机码，再次向服务器发送确认信息(ACK=1)，当服务器接收到确认信息后，TCP完成建立连接。 ##四次挥手第一次挥手，客户端想服务器端发出请求，信息FIN=1，表示要断开连接第二次挥手，服务器端接受到请求进入CLOSE-WAIT(关闭等待状态)，此时客户端已经没有数据要发送了，但是服务器若要发送数据，客户端依然能接受。第三次挥手，服务器数据发送完毕，就向客户端发送连接释放报文，此时服务器进入最后确认状态，等待客户端的确认第四次挥手，客户端接收到服务器的连接释放报文后，发送ACK=1确认信息，此时客户端进入TIME-WAIT状态，经过2*MSL（最长报文寿命）的时间后，客户端断开连接 ##状态码 ###2XX 成功状态码，请求正常处理完毕 200 OK，表示从客户端发来的请求在服务器端正常处理了 204 No Content，该状态码代表服务器接受的请求已经处理成功，但在返回的相应报文中，不含实体的主题部分，另外也不允许返回任何实体的主体，比如当浏览器发出请求处理后，返回204状态码，那么浏览器显示的页面不会发生更新。 206 Partial Contetn，该状态码表示客户端进行了范围请求，而服务器成功的执行了这部分的GET请求。相应报文中包含由Contetn-Range指定范围的实体内容###3XX 重定向状态码，需要进行附加操作完成请求 301 Moved Permanently 永久重定向，该状态码表示请求的资源已分配了新的URL，以后应使用资源现在指向的URL。 302 Found 临时重定向，该状态码表示请求的资源已分配了新的URL，希望本次使用新的URL。 303 See Other 该状态码用于请求对应的资源存在另一个URL，应使用GET方法定向获取请求的资源。 304 Not Modified 该状态码表示客户端发送附带条件的请求时，服务器端允许请求访问资源，但为满足条件的情况。在客户端向服务端发送http请求时，若返回状态码为304 Not Modified 则表明此次请求为条件请求。在请求头中有两个请求参数：If-Modified-Since 和 If-None-Match。当客户端缓存了目标资源但不确定该缓存资源是否是最新版本的时候, 就会发送一个条件请求。在进行条件请求时,客户端会提供给服务器一个If-Modified-Since请求头,其值为服务器上次返回响应头中Last-Modified值,还会提供一个If-None-Match请求头,值为服务器上次返回的ETag响应头的值。服务器会读取到这两个请求头中的值,判断出客户端缓存的资源是否是最新的,如果是的话,服务器就会返回HTTP/304 Not Modified响应头, 但没有响应体.客户端收到304响应后,就会从本地缓存中读取对应的资源。 所以：当访问资源出现304访问的情况下其实就是先在本地缓存了访问的资源。###4XX 客户端错误状态码，服务器无法处理请求 400 Bad Request 该状态码表示请求报文中存在语法错误，当错误发生时，需修改请求的内容后再次发送请求。 401 Unauthorized 该状态码表示发送的请求需要通过HTTP认证的认证信息 403 Forbidden 该状态码表示对请求的资源的访问被服务器拒绝了，服务器端没必要给出拒绝的详细理由，但是如果想做说明的话，可以在实体的主体部分对原因进行描述。 404 Not Found 该状态码表明服务器上无法找到请求的资源。###5XX 服务器错误状态码，服务器请求处理出错 500 Internal Server Error 该状态码表明服务器端在执行请求的时候发生了错误，也有可能是web应用存在的bug或临时故障。 503 Service Unavailable 该状态表明服务器暂时处于超负载或正在进行停机维护，现在无法处理请求##通信数据转发程序###代理 代理是一种具有转发功能的应用程序，扮演了位于服务器和客户端“中间人”的角色，接收由客户端发送的请求并转发给服务器，同时也接收服务器的响应并转发给客户端。代理服务器的基本行为就是接收客户端发来的请求并转发给其他服务器，代理不改变请求的URL，会直接发送给前方持有资源的目标服务器。持有资源的目标服务器接收到请求后返回的相应经过代理服务器后传回给客户端。在HTTP通信的过程中，可级联多台代理服务器，请求和相应的转发会经过数台类似锁链一样的连接起来的代理服务器。转发时需要附加Via首部字段表标出经过的主机信息。###网关 网关是转发其他服务器通信数据的服务器，接收从客户端发来的请求时，它就像自己拥有资源的服务器一样对请求进行处理。有时客户端可能都不会察觉，自己通信的目标是一个网关。利用网关可以由HTTP请求转换为其他协议通信利用网关可以提高通信的安全性， 因为可以在客户端与网关之间的通信线路上加密以确保连接的安全，比如网关可以连接数据库，另外在WEB购物网站上进行信用卡结算时，网关可以和信用卡结算系统联动。###隧道 隧道是在相隔甚远的客户端和服务器两者之间进行中转，并保持双方通信连接的应用程序。隧道可以按要求建立起一条与其他服务器的通信线路，届时使用SSL等加密手段进行通信，隧道的目的是确保客户端能与服务器进行安全的通信。##通用首部字段###Cache-Control 操作缓存的工作机制public：明确表示其他用户也可以使用该缓存private：响应只以特定用户作为对象no-cache：no-cache不代表客户端不进行缓存，客户端依旧进行缓存，只是在每次使用资源的时候需要向服务器确认下资源可用否，可用的话服务器将不再返回新的资源，客户端使用缓存no-store：告诉客户端不要进行缓存max-age：设置缓存的最长时间s-max-age：和max-age指令相同，但是用于代理服务器（CDN），s-max-age的优先级高于max-age，如果存在s-max-age，则会覆盖掉max-age和Expires header。min-fresh：要求缓存服务器返回至少还未过指定时间的缓存资源，比如指定了min-fresh为60秒后，过了60秒的资源都无法返回了。max-stale：使用max-stale，可指示缓存资源，即使过期但是只要不超过max-stale的值，依旧返回给客户端only-if-cached：仅在缓存服务器本地缓存目标资源的情况下才会要求返回，若发生请求缓存服务器的本地缓存无响应，则返回状态码504must-revalidate：会向服务器再次验证即将返回的响应缓存目前是否依然有效，若无法连通服务器再次获取有效资源的话，缓存必须给客户度一条504状态码。使用了must-revalidate会忽略max-staleproxy-revalidate：要求所有缓存服务器在接收到客户端带有该指令的请求返回响应前，必须再次校验缓存的有效性no-transform：Content-Encoding, Content-Range, Content-Type等HTTP头不能由代理修改###connection 控制不再转发给代理的首部字段 管理持久连接###Upgrade用于检测HTTP协议及其他协议是否可以使用更高的版本进行通信，其参数值可以用来指定一个完全不同的通信协议，使用时connection需要指定为upgrade###Transfer-Encoding规定了传输报文主体时采用的编码方式。HTTP/1.1的传输编码方式仅对分块传输数据有效###Via使用首部字段Via是为了追踪客户端和服务器之间的请求和相应报文的传输路径。报文经过代理或网关时，会先在首部Via中附加该服务器的信息，然后再进行转发，首部Via不仅可以用于追踪报文的转发，还可以避免请求回环的发生。##请求首部字段 请求首部字段是从客户端发送请求报文中所使用的字段，用于补充请求的附加信息，客户端信息，对响应内容相关的优先级内容Accept Accept首部字段可以通知服务器，用户代理能够处理的媒体类型及媒体类型的相对优先级text/html,text/plain,text/cssapplication/xhtml+xml,application/xmlimage/jpeg,image/png,image/gif###Accept-Charset Accept-Charset首部字段可以用来通知服务器用户代理支持的字符集及字符集的相对优先顺序。Accept-Charset:iso-8859-5,unicode-1-1;q=0.8(q用来表示优先级)###Accpet-Encoding Accept-Charset首部字段用来告知服务器用户代理支持的内容编码及内容编码的优先级顺序，可以一次性指定多个内容编码。 gzip compress deflate identity###Accept-Language Accept-Language首部字段用来告知服务器用户代理能够处理的自然语言集，以及自然语言集的相对优先级，可以一次指定多个自然语言集。Accept-Language:zh-cn;q=0.7,en-us,en;q=0.3###Authorization Authorization首部字段是用来告诉服务器，用户代理的认证信息###From 用来告知服务器使用用户代理的用户的电子邮件地址。From:xxx@qq.com###Host 首部字段Host告诉服务器，请求的资源所处的互联网主机名和端口号。 Host首部字段在HTTP/1.1范围内是唯一一个必须包含在请求内的首部字段 首部字段Host和以单台服务器分配多个域名的虚拟主机工作机制有很密切的关系，这是HOST必须存在的意义###If-Match（与If-None-Match相反） 服务器会对比If-Match和ETag的值，仅当两个值一致时，才会执行请求，反之，则返回412Precodition Failed的响应。还可以使用*指定If-Match的值，针对这种情况，服务器会忽略ETag的值，只要资源存在就请求处理。###If-Modified-Since(与If-Unmodified-Since相反) 如果在指定的时间之后，资源发生了更新，服务器会接受请求否则不会。 可以通过Last-Modified来确定资源的更新日期###Max-Forwards 可以指定最多转发次数###Range 告知服务器资源的指定范围，可以只获取部分资源Range:bytes=5001-10000###Referer 告知服务器请求的原始资源uriReferer:http://www.baidu.com###User-Agent 用于传达浏览器种类###Cookie 首部字段Cookie，会告知服务器，当客户端想获得HTTP状态管理支持时，就会在请求中包含从服务器接收到的Cookie，接收到多个Cookie时，同样可以以多个Cookie形式发送。##响应首部字段###Accept-Ranges 用来告知客户端服务器是否能处理范围请求，可指定的字段值有两种，可处理范围请求时指定其为bytes，反之指定为none###Age 用来告知客户端，源服务器在多久前创建了响应。字段值的单位为秒。###ETag 用来告知客户端实体标识，是一种可将资源以字符串形式作唯一标识的方式，服务器会为每份资源配置对应的ETag，资源更新时也需要更新ETag###Location 可以将响应接收方引导至某个与请求URI位置不同的资源。 基本上该字段都会配合3xx：Redirection的相应提供重定向的URI###Server 告知客户端当前服务器上安装的HTTP服务器应用程序的信息。###Set-Cookie 当服务器准备开始管理客户端的状态时，会事先告知各种信息。字段属性值 NAME=VALUE 赋予Cookie的名称和其值（必需项） expires=Date Cookie的有效期（若不明确指定则默认为浏览器关闭前） path=PATH将服务器上的文件目录作为Cookie的适用对象 domain=域名 作为Cookie适用对象的域名 Secure 仅在HTTPS安全通信时才会发送Cookie HttpOnly 加以限制，使Cookie不能被Javascript脚本访问 Set-Cookie:name=value;HttpOnly##实体首部字段 实体首部字段是包含在请求报文和响应报文中的实体部分所使用的首部，用于补充内容的更新时间与实体相关的信息，在请求和响应两方的HTTP报文中都含有与实体相关的首部字段###Allow 用于通知客户端能够支持的Request-URI指定资源的所有HTTP方法，当状态码接收到不支持的HTTP方法时，会以状态码405 Method Not Allowed作为响应返回。###Content-Language 首部字段Content-Language会告知客户端，实体主体使用的自然语言###Content-Range 针对范围请求，返回响应时使用的首部字段Contetn-Range,能告知客户端作为响应返回的实体的哪个部分符合范围请求。Content-Range:bytes 5001-10000/10000###Content-Type 说明了实体主体内对象的媒体类型。###Expires 首部字段Expires会将资源失效的日期告知客户端，缓存服务器在接收到含有首部字段Expires的响应后，会以缓存来应答请求，在Expires字段值指定的时间前，响应的副本会一直被保存，当超过指定时间后，缓存服务器在请求发送过来时，会转向源服务器请求资源。 源服务器不希望缓存服务器对资源缓存时，最好在Expires字段内写入首部字段Date相同的时间值。 但是，当首部字段Cache-Control有指令max-age指令时，比起首部字段expires，会优先处理max-age指令。###Last-Modified 首部字段Last-Modified指明资源最终修改的时间，一般来说这个值就是Request-URI指定资源被修改的时间。但类似使用CGI脚本进行动态数据处理时，该值有可能会变成数据最终修改时的时间。]]></content>
      <categories>
        <category>计算机网络</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[开发中的常见问题【陆续整理】]]></title>
    <url>%2F2019%2F06%2F05%2F%E5%BC%80%E5%8F%91%E4%B8%AD%E7%9A%84%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98%E3%80%90%E9%99%86%E7%BB%AD%E6%95%B4%E7%90%86%E3%80%91%2F</url>
    <content type="text"><![CDATA[开发中的常见问题【陆续整理】##204问题 项目都是前后端分离的，上线几个月以来，发现一个很奇怪的问题，每次前端发起请求，通过浏览器的开发者工具都能看到在Network下同一个url有两条请求，第一条请求的Method为OPTIONS，第二条请求的Method才是真正的GET或者POST，并且，第一条请求无数据返回，第二条请求才会返回正常的数据。发现这个问题之后，立即组织搜索问题产生的原因以及解决方案。在网上搜索了大量资料，得到的一个结论是：第一个OPTIONS的请求是由Web服务器处理跨域访问引发的。网上资料显示，OPTIONS是一种“预检请求”，浏览器在处理跨域访问的请求时如果判断请求为复杂请求，则会先向服务器发送一条预检请求，根据服务器返回的内容浏览器判断服务器是否允许该请求访问。如果web服务器采用cors的方式支持跨域访问，在处理复杂请求时这个预检请求是不可避免的。 查询代码发现，我们的web服务器确实采用的是cors来解决跨域访问的问题，并且我们在header中添加了自定义参数，导致我们的每次请求都为复杂请求，从而产生了每次请求都会发送两条请求的现象。 问题的原因找到了，就要想办法解决这个问题。既然浏览器在处理复杂请求时，不可避免的要发送预检请求，那么能否减少预检请求的次数呢？比如，预检一次设置一个有效期，在有效期内不再重复预检。顺着这个思路，继续搜索相关资料，最终发现设置Access-Control-Max-Age这个参数即可达到预期目标。该参数用来指定本次预检请求的有效期，单位为秒。在服务器上设置该参数之后，问题解决了，大快人心！！！参考资料：https://blog.csdn.net/charleslei/article/details/51906635]]></content>
      <tags>
        <tag>工作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一次被老婆XX的经历]]></title>
    <url>%2F2019%2F06%2F03%2F%E4%B8%80%E6%AC%A1%E8%A2%AB%E8%80%81%E5%A9%86XX%E7%9A%84%E7%BB%8F%E5%8E%86%2F</url>
    <content type="text"><![CDATA[最美的不在窗外而在眼前 第三次来到这座城市第一次的兴奋第二次的迷茫这一次的自由自由是因为有我最爱的你陪伴自由是因为清晰了未来想要的生活 没有去太多的地方，超过了50%的时间就在酒店里没有吃太多的美食，甚至几餐都吃的外卖但是感受了几天和你朝夕相伴的时光，于我而言，这样的旅行是接近完美的，只因为有你的陪伴，唯一不足的是安排好行程，你应该多少有点失望吧，还是想写下没有去做的原因，毕竟这座城市是你和别人先来的，我不知道你们去过哪些地方，我害怕同样的地点会勾起你的回忆 好在未来还很长，这世界上还有太多的地方等着我们去开发，因为有你所以自由，因为有你未来可期]]></content>
      <tags>
        <tag>爱情</tag>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我们的故事]]></title>
    <url>%2F2019%2F05%2F21%2F%E6%88%91%E4%BB%AC%E7%9A%84%E6%95%85%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[我们的故事 今天是2019.05.21 特别的日子，此文用于记录我们之间的点滴 2019.05.21今天在地铁上，快到世纪城了，我故意把你抱紧，希望你不要去寻找，希望你不要推开我，但能感觉到你还是有去寻找，但是我没办法告诉你，因为我害怕这一切都只是我自己太敏感的幻想。你说我生气了，并没有，我只是不清楚你心中的想法。陪你洗了头，回家的路上，你问，以后我们能养得起我们的娃么？我说要看怎么养了，我也没养过。放心吧，我一定会200%的努力工作，养你，养娃。半年快乐~ 2019.06.03今天开始强行逼自己加班学习，虽然很想立马去见你，拥抱你，但是比起短暂的现在，我希望能给你美好的未来。多希望睡前有你，醒来你还在的日子早点到来。刚吃了饭，再坚持一个半小时就能见到你了，加油鸭！见了你，虽然表面波澜不惊，但是内心早已汹涌澎湃了，哈哈哈哈哈哈，开心回家跑了步，再学习一会儿就睡觉啦，醒来又可以见到你了，明天给你做南瓜粥鸭 2019.06.05快下班了，你发消息问我晚上吃什么，本来想说我已经吃过了，但是又想和你一起吃个晚饭，所以告诉你我想吃凉面，嘻嘻嘻，其实我已经吃过凉面啦我自己吃的凉面 我们一起吃的冷沾沾 我们一共吃了27个冷沾沾，你问我吃饱没，其实我已经撑啦，幸福就是能和你一起吃早餐和晚餐!]]></content>
      <tags>
        <tag>爱情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之——观察者模式]]></title>
    <url>%2F2019%2F05%2F17%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E2%80%94%E2%80%94%E8%A7%82%E5%AF%9F%E8%80%85%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[顾名思义，观察者模式可以用于监控一个程序的变动，从而做出对应的逻辑。 需求：登录是绝大数产品中拥有的功能，也是很重要的功能，当前我们已经实现了一个登录的方法可以完成登录的基本功能，见如下代码12345678910&lt;?phpclass Login&#123; public function doLogin() &#123; if(rand(1,2)==1) &#123; echo '假装登录成功'; &#125; &#125;&#125; 好了，当前我们已经拥有了登录的方法了，这个时候产品经理又提出在登录成功后我们需要记录下用户的ip，那么程序员小哥哥们又是一波操作，把代码改成了下面这样。 12345678910111213141516&lt;?phpclass Login&#123; public function doLogin() &#123; if(rand(1,2)==1) &#123; echo '假装登录成功'; $this-&gt;doLog(); &#125; &#125; public function doLog() &#123; echo '记录ip'; &#125;&#125; 这个时候我们有了记录ip的方法，产品经理又提出，我们要在失败的时候记录下用户登录失败的原因，fine… 996走一波1234567891011121314151617181920212223&lt;?phpclass Login&#123; public function doLogin() &#123; if(rand(1,2)==1) &#123; echo '假装登录成功'; $this-&gt;doLog(); &#125;else &#123; $this-&gt;doError(); &#125; &#125; public function doLog() &#123; echo '记录ip'; &#125; public function doError() &#123; echo 'why？？？'; &#125;&#125; 通过两次的迭代，小哥哥为我们的登录模块添加上了记录ip和记录错误的功能，我们可以发现这种迭代的方法完全违背了代码的开闭原则，我们每次的功能调整都会影响到原有的login方法，所以在这种情况下，我们的观察者模式就登上了舞台。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182&lt;?phpnamespace Observer;interface Observerable&#123; public function attach(Observer $observer); public function detach(Observer $observer); public function notify();&#125;interface Observer&#123; public function update(Observerable $observerable);&#125;class Login implements Observerable&#123; private $observers; private $status; public function __construct() &#123; $this-&gt;status = rand(1,2); &#125; public function getStatus() &#123; return $this-&gt;status; &#125; public function attach(Observer $observer) &#123; $this-&gt;observers[] = $observer; &#125; public function detach(Observer $observer) &#123; $newObservers = []; foreach($this-&gt;observers as $o) &#123; if($o !== $observer) &#123; $newObservers[] = $o; &#125; &#125; $this-&gt;observers = $newObservers; &#125; public function notify() &#123; foreach($this-&gt;observers as $o) &#123; $o-&gt;update($this); &#125; &#125;&#125;class LoginLogObserver implements Observer&#123; public function update(Observerable $observerable) &#123; if($observerable-&gt;getStatus()==1) &#123; echo '记录ip更灵活'; &#125; &#125;&#125;class LoginErrObserver implements Observer&#123; public function update(Observerable $observerable) &#123; if($observerable-&gt;getStatus()==2) &#123; echo 'NO WHY'; &#125; &#125;&#125;$login = new Login();$login-&gt;attach(new LoginLogObserver());$login-&gt;attach(new LoginErrObserver());$login-&gt;notify(); 在最新版本的代码中，我们重构了代码，按照观察者模式说先我们定义了一个可被观察的接口，要求实现该接口的类必须包含添加观察者，移除观察者，观察者执行的三个方法。同时我们定义了一个观察者的接口，要求实现该接口的类必须包含更新方法用于同步被观察者的操作。定义好接口后，我们定义了实现类，登录类实现被观察者接口，日志记录类，错误记录类实现了观察者接口。此时我们的代码比之前灵活了很多，通过组合的方式，我们可以很灵活的添加和删除对登录方法的监控，并且完全不会影响到登录的逻辑，满足了开闭原则。]]></content>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[心静如水]]></title>
    <url>%2F2019%2F05%2F16%2F%E5%BF%83%E9%9D%99%E5%A6%82%E6%B0%B4%2F</url>
    <content type="text"><![CDATA[夏日的标配大概就是西瓜🍉配音乐🎵吧 结束了一天的工作，冲洗掉了一身的汗渍，坐在离小胡最近的位置，听歌，看书，吃水果。很久没有一个人这么安静的坐着干自己的事情了，这里的安静指心中的安静，至于为什么能够安静大概是因为我知道小胡已经入睡了，因此我不用操心她熬夜伤身的问题了，今天的工作完成了，因此我不用担心还有没改完的bug的问题了，今天的训练完成了，因此我不用担心这个点吃西瓜会长胖的问题了(虽然确实可能会长胖)，总结一下大概是因为在这一刻几乎没有了任何的欲望吧。如果人能控制自己的欲望，是不是就能一直保持这样的状态了呢？那无欲无求的人是不上进的咸鱼还是看透一切的大师呢？]]></content>
      <tags>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之——外观模式]]></title>
    <url>%2F2019%2F05%2F14%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E2%80%94%E2%80%94%E5%A4%96%E8%A7%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[外观模式（Facade）,他隐藏了系统的复杂性，并向客户端提供了一个可以访问系统的接口。这种类型的设计模式属于结构性模式。为子系统中的一组接口提供了一个统一的访问接口，这个接口使得子系统更容易被访问或者使用。 我们当前有一个需求是完成用户的购票功能，逻辑是用户需要先登录，然后选票，然后进行验证码校验，最后完成支付 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?phpclass User&#123; public function doLogin() &#123; echo '先登录'; &#125;&#125;class Ticket&#123; public function getTicket() &#123; echo '选票'; &#125;&#125;class Verify&#123; public function doVerify() &#123; echo '验证码'; &#125;&#125;class Pay&#123; public function doPay() &#123; echo '支付'; &#125;&#125;$user = new User();$user-&gt;doLogin();$ticket = new Ticket();$ticket-&gt;getTicket();$verify = new Verify();$verify-&gt;doVerify();$pay = new Pay();$pay-&gt;doPay(); 在当前版本中，我们分别定义了四个类，每个类负责各自的功能，当客户端需要实现业务逻辑的时候显得比较麻烦，特别是当有多处地方进行该业务操作的时候，如果业务逻辑发生了变动，所有地方都需要进行修改，因此我们对代码进行了修改。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?phpclass User&#123; public function doLogin() &#123; echo '先登录'; &#125;&#125;class Ticket&#123; public function getTicket() &#123; echo '选票'; &#125;&#125;class Verify&#123; public function doVerify() &#123; echo '验证码'; &#125;&#125;class Pay&#123; public function doPay() &#123; echo '支付'; &#125;&#125;class HN&#123; public function buyTicket() &#123; $user = new User(); $user-&gt;doLogin(); $ticket = new Ticket(); $ticket-&gt;getTicket(); $verify = new Verify(); $verify-&gt;doVerify(); $pay = new Pay(); $pay-&gt;doPay(); &#125;&#125;$hn = new HN();$hn-&gt;buyTicket(); 在新的版本中，我们创建了一个黄牛类来帮助我们买票，黄牛的buyTicket方法完成了所有的业务逻辑，因此客户端在任何地方只需要委托黄牛来帮助完成购票的功能即可。 这种方式既外观模式，通过封装交互，简化调用]]></content>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之——装饰器模式]]></title>
    <url>%2F2019%2F05%2F13%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E2%80%94%E2%80%94%E8%A3%85%E9%A5%B0%E5%99%A8%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[装饰器模式是一种用于代替继承的技术，无需通过继承增加子类就能扩展对象的新功能。使用对象的关联关系代替继承关系，更加灵活，同时避免类型体系的快速膨胀。&lt; !–more–&gt; 示例代码123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;?phpabstract class Car&#123; public abstract function run();&#125;abstract class DerectoreBase extends Car&#123; protected $car; public function __construct(Car $car) &#123; $this-&gt;car = $car; &#125;&#125;class ColorDerector extends DerectoreBase&#123; public function run() &#123; echo "颜色\n"; $this-&gt;car-&gt;run(); &#125;&#125;class SpeedDerector extends DerectoreBase&#123; public function run() &#123; echo "速度\n"; $this-&gt;car-&gt;run(); &#125;&#125;class Benz extends Car&#123; public function run() &#123; echo "This is Benz"; &#125;&#125;$tmp = new ColorDerector(new SpeedDerector(new Benz()));$tmp-&gt;run(); 在上面的代码中，我们首先定义了一个基类，并且有一个run的抽象方法，其他类都继承于该类。然后创建了一个装饰器的基类，该类中有一个car的属性，用于保存被修饰的对象。接着我们创建了两个具体的装饰类用于实现具体的装饰功能然后我们创建了一个奔驰类继承了汽车基类此时我们通过实例化装饰类并且把奔驰类作为参数传入就可以实现装饰功能，以及多级装饰功能。]]></content>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之——组合模式]]></title>
    <url>%2F2019%2F05%2F06%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E2%80%94%E2%80%94%E7%BB%84%E5%90%88%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"></content>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[设计模式之——工厂模式]]></title>
    <url>%2F2019%2F04%2F30%2F%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8B%E2%80%94%E2%80%94%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%2F</url>
    <content type="text"></content>
      <tags>
        <tag>设计模式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019读书计划]]></title>
    <url>%2F2019%2F01%2F01%2F%E8%AF%BB%E4%B9%A6%E8%AE%A1%E5%88%92%2F</url>
    <content type="text"><![CDATA[专业 深入PHP面向对象、模式与实践(第2版) GO语言编程 图解HTTP 深入浅出Docker Docker——容器与容器云 Modern PHP 大型网站技术架构 淘宝技术那十年 穿越计算机的迷雾 深入理解RPC：自建分布式高并发RPC服务 高性能MySQL Kafka权威指南 Redis设计与实现 数据结构与算法分析 操作系统 程序员的自我修养 其他 我们仨 挪威的森林 活着 断舍离 白夜行 禅者的初心 数学之美 代码整洁之道 软技能 : 代码之外的生存指南 心流 程序员的职业素养 终身成长 重构 : 改善既有代码的设计 生命3.0 程序员的思维修炼 : 开发认知潜能的九堂课 护理札记]]></content>
      <tags>
        <tag>学习</tag>
      </tags>
  </entry>
</search>
